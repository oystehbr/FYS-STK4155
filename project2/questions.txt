Spørsmål til Morten:
- Scaling the data
- Correct activation function overall
- momentum in stochastic GD? will it work?




MAYBE ANSWERED
-------------------------
- Scaling the data
- oppdatere learning rate? bra metode
- derivere sigmoid???
- en bias per layer eller flere?
- hvor mye momentum er bra?
- når skjer overfitting?


- skal vi ha samme antall neurons i alle hidden layers?
- Loop over learning rates vs learning rate algoritm
- stchocastic: hvordan mekke gradient matriser
---------------------------



NEW, 31.okt:
------------------------
- Shall the code be able to predict more than 1 output value?
- RELU, Leaky_RELU -> trash, enten predicte same values, or exploding results. 