# FYS-STK3155/4155 Project 2 Feedback
## Students
- 

## Abstract:
The abstract could have gone into a little more specifics on what was done to compare the models and lacked a summary of the most important results

Score: 3/5 points

## Introduction: 
Very good that the introduction included the structure of the report!
The introduction lacked some motivation for why this research is important.

You do explain what is done in the project, which is very good. Try also to explain to the reader why you have done what you did as well.

This section would also be a good place to mention the data sets.

Score: 7/10 points

## Formalism:
Remember to explain what the variables in your equations are. What is y hat in eq. 1 for example? And what does the R2 score tell you? You did this for the most of the methods section, which is good!

Very good that you write an introduction for each subsection.

Gradient descent:
What is the hyperparameter lambda?
Very nice that you gave a motivation for each of the methods!

Neural network:
3.3.4: The mathematics of the feed forward algorithm could have been introduced here.
3.3.5: What is the purpose of activation functions?
3.3.6: Here you have not explained most of the parameters. A reader new to neural networks would have trouble understanding what is going on in the backpropagation algorithm.
3.4: It would have been nice with the equation for the gradient of the cost function here. It might not be entirely apparent for the reader how logistic regression works. Especially the training of the algorithm.



Score: 15/20 points

## Code, implementation and testing:
Very nice!
Well documented and easy to read.

Score: 20/20 points

## Analysis:


4.1.3: Remember to state the fraction of samples belonging to each class. This is important to understand how good a given accuracy score is.

Fig 2: 'We observe that the optimal learning rate is around 0.1 or 0.01 for this case, as this gives the highest R2-score. As a result of that, it will be the closest one to the analytical solution.'
This is not true. When noise is introduced to the data set, the model might fit to the noise. The R2 on the training data can then be high, but the model might not generalize well to unseen data.

'By looking at figure 3, 4 and 5 we can confirm that higher number of iterations in the SGD-algorithm will lead to a better result.'
These figures are not sufficient to show convergence. It would have been better to show a plot of the training and testing MSE against epoch nr.

4.2.1: Very good

4.2.3: What does node list specify? This needs to be explained.
'We tried to find a region where the architecture was kind of stable and worked good as a model, those values were 40 hidden nodes and 3 hidden layers.'
A neural network with 39 nodes and 2 layers is a different model than 40 nodes and 3 layers, so I do not think it is necessary to find a 'stable area' on these heatmaps.

4.3.1.1: Fig. 25, 26, 27 can probably be combined into one plot.


You provided lots of heatmaps which apparently did not show any obvious pattern / relationships between the hyperparameters studied. When seeing this it might be a good idea to just to a grid search between all the hyperparameters and list the optimal parameters along with the optimal MSE in a table for example. Some of the figures did hence not provide significant insight to the model or data. Theese may have instead been included in an appendix to show that you did do a search.


You do not need to specify which scripts to run in the analysis section. How to produce your results should be clear from the theory and the mentioned grid of hyperparameters. You could instead explain this in the readme on github if you want to.


Very good that you mention that runtime warnings did occur!

Otherwise, really good that you tried so many different neural network architectures and studied the effect of different hyperparameters. 


Score: 16/20 points

## Conclusions:
Very good conclusion! 
Score: 10/10 points

## Overall presentation:
The methods section provided a mixture of theory and explanation of the code. This is ok, but the code was explained before the theory was, which means that a reader not familiar with the theory would not understand the explanation of the code. The structure would have made more sense if the code was explained after the theory.

Remember to restate the full name of abbreviations in every section and also what hyperparameters different greek symbols belong to. This information is not easy to remember for all readers.

You have a lot of unnecessary whitespace in the report, partly from space after figures and partly from very large margins. Remember that you can adjust this in Latex. 

Score 9/10 points

## Referencing:
Score: 5/5 points



## Overall:


Final score : 85/100 points
