{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "[Video of Lecture](https://www.uio.no/studier/emner/matnat/fys/FYS-STK3155/h20/forelesningsvideoer/LectureAug21.mp4?vrtx=view-as-webpage)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our emphasis throughout this series of lectures (small change)  \n",
    "is on understanding the mathematical aspects of\n",
    "different algorithms used in the fields of data analysis and machine learning. \n",
    "\n",
    "However, where possible we will emphasize the\n",
    "importance of using available software. We start thus with a hands-on\n",
    "and top-down approach to machine learning. The aim is thus to start with\n",
    "relevant data or data we have produced \n",
    "and use these to introduce statistical data analysis\n",
    "concepts and machine learning algorithms before we delve into the\n",
    "algorithms themselves. The examples we will use in the beginning, start with simple\n",
    "polynomials with random noise added. We will use the Python\n",
    "software package [Scikit-Learn](http://scikit-learn.org/stable/) and\n",
    "introduce various machine learning algorithms to make fits of\n",
    "the data and predictions. We move thereafter to more interesting\n",
    "cases such as data from say experiments (below we will look at experimental nuclear binding energies as an example).\n",
    "These are examples where we can easily set up the data and\n",
    "then use machine learning algorithms included in for example\n",
    "**Scikit-Learn**. \n",
    "\n",
    "These examples will serve us the purpose of getting\n",
    "started. Furthermore, they allow us to catch more than two birds with\n",
    "a stone. They will allow us to bring in some programming specific\n",
    "topics and tools as well as showing the power of various Python \n",
    "libraries for machine learning and statistical data analysis.  \n",
    "\n",
    "Here, we will mainly focus on two\n",
    "specific Python packages for Machine Learning, Scikit-Learn and\n",
    "Tensorflow (see below for links etc).  Moreover, the examples we\n",
    "introduce will serve as inputs to many of our discussions later, as\n",
    "well as allowing you to set up models and produce your own data and\n",
    "get started with programming.\n",
    "\n",
    "\n",
    "\n",
    "## What is Machine Learning?\n",
    "\n",
    "Statistics, data science and machine learning form important fields of\n",
    "research in modern science.  They describe how to learn and make\n",
    "predictions from data, as well as allowing us to extract important\n",
    "correlations about physical process and the underlying laws of motion\n",
    "in large data sets. The latter, big data sets, appear frequently in\n",
    "essentially all disciplines, from the traditional Science, Technology,\n",
    "Mathematics and Engineering fields to Life Science, Law, education\n",
    "research, the Humanities and the Social Sciences. \n",
    "\n",
    "It has become more\n",
    "and more common to see research projects on big data in for example\n",
    "the Social Sciences where extracting patterns from complicated survey\n",
    "data is one of many research directions.  Having a solid grasp of data\n",
    "analysis and machine learning is thus becoming central to scientific\n",
    "computing in many fields, and competences and skills within the fields\n",
    "of machine learning and scientific computing are nowadays strongly\n",
    "requested by many potential employers. The latter cannot be\n",
    "overstated, familiarity with machine learning has almost become a\n",
    "prerequisite for many of the most exciting employment opportunities,\n",
    "whether they are in bioinformatics, life science, physics or finance,\n",
    "in the private or the public sector. This author has had several\n",
    "students or met students who have been hired recently based on their\n",
    "skills and competences in scientific computing and data science, often\n",
    "with marginal knowledge of machine learning.\n",
    "\n",
    "Machine learning is a subfield of computer science, and is closely\n",
    "related to computational statistics.  It evolved from the study of\n",
    "pattern recognition in artificial intelligence (AI) research, and has\n",
    "made contributions to AI tasks like computer vision, natural language\n",
    "processing and speech recognition. Many of the methods we will study are also \n",
    "strongly rooted in basic mathematics and physics research. \n",
    "\n",
    "Ideally, machine learning represents the science of giving computers\n",
    "the ability to learn without being explicitly programmed.  The idea is\n",
    "that there exist generic algorithms which can be used to find patterns\n",
    "in a broad class of data sets without having to write code\n",
    "specifically for each problem. The algorithm will build its own logic\n",
    "based on the data.  You should however always keep in mind that\n",
    "machines and algorithms are to a large extent developed by humans. The\n",
    "insights and knowledge we have about a specific system, play a central\n",
    "role when we develop a specific machine learning algorithm. \n",
    "\n",
    "Machine learning is an extremely rich field, in spite of its young\n",
    "age. The increases we have seen during the last three decades in\n",
    "computational capabilities have been followed by developments of\n",
    "methods and techniques for analyzing and handling large date sets,\n",
    "relying heavily on statistics, computer science and mathematics.  The\n",
    "field is rather new and developing rapidly. Popular software packages\n",
    "written in Python for machine learning like\n",
    "[Scikit-learn](http://scikit-learn.org/stable/),\n",
    "[Tensorflow](https://www.tensorflow.org/),\n",
    "[PyTorch](http://pytorch.org/) and [Keras](https://keras.io/), all\n",
    "freely available at their respective GitHub sites, encompass\n",
    "communities of developers in the thousands or more. And the number of\n",
    "code developers and contributors keeps increasing. Not all the\n",
    "algorithms and methods can be given a rigorous mathematical\n",
    "justification, opening up thereby large rooms for experimenting and\n",
    "trial and error and thereby exciting new developments.  However, a\n",
    "solid command of linear algebra, multivariate theory, probability\n",
    "theory, statistical data analysis, understanding errors and Monte\n",
    "Carlo methods are central elements in a proper understanding of many\n",
    "of algorithms and methods we will discuss.\n",
    "\n",
    "\n",
    "\n",
    "The approaches to machine learning are many, but are often split into\n",
    "two main categories.  In *supervised learning* we know the answer to a\n",
    "problem, and let the computer deduce the logic behind it. On the other\n",
    "hand, *unsupervised learning* is a method for finding patterns and\n",
    "relationship in data sets without any prior knowledge of the system.\n",
    "Some authours also operate with a third category, namely\n",
    "*reinforcement learning*. This is a paradigm of learning inspired by\n",
    "behavioral psychology, where learning is achieved by trial-and-error,\n",
    "solely from rewards and punishment.\n",
    "\n",
    "Another way to categorize machine learning tasks is to consider the\n",
    "desired output of a system.  Some of the most common tasks are:\n",
    "\n",
    "  * Classification: Outputs are divided into two or more classes. The goal is to   produce a model that assigns inputs into one of these classes. An example is to identify  digits based on pictures of hand-written ones. Classification is typically supervised learning.\n",
    "\n",
    "  * Regression: Finding a functional relationship between an input data set and a reference data set.   The goal is to construct a function that maps input data to continuous output values.\n",
    "\n",
    "  * Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand.  It is thus a form of unsupervised learning.\n",
    "\n",
    "The methods we cover have three main topics in common, irrespective of\n",
    "whether we deal with supervised or unsupervised learning.\n",
    "* The first ingredient is normally our data set (which can be subdivided into training, validation  and test data). Many find the most difficult part of using Machine Learning to be the set up of your data in a meaningful way. \n",
    "\n",
    "* The second item is a model which is normally a function of some parameters.  The model reflects our knowledge of the system (or lack thereof). As an example, if we know that our data show a behavior similar to what would be predicted by a polynomial, fitting our data to a polynomial of some degree would then determin our model. \n",
    "\n",
    "* The last ingredient is a so-called **cost/loss** function (or error or risk function) which allows us to present an estimate on how good our model is in reproducing the data it is supposed to train.  \n",
    "\n",
    "\n",
    "\n",
    "At the heart of basically all Machine Learning algorithms we will encounter so-called minimization or optimization algorithms. A large family of such methods are so-called **gradient methods**.\n",
    "\n",
    "\n",
    "### A Frequentist approach to data analysis\n",
    "\n",
    "When you hear phrases like **predictions and estimations** and\n",
    "**correlations and causations**, what do you think of?  May be you think\n",
    "of the difference between classifying new data points and generating\n",
    "new data points.\n",
    "Or perhaps you consider that correlations represent some kind of symmetric statements like\n",
    "if $A$ is correlated with $B$, then $B$ is correlated with\n",
    "$A$. Causation on the other hand is directional, that is if $A$ causes $B$, $B$ does not\n",
    "necessarily cause $A$.\n",
    "\n",
    "These concepts are in some sense the difference between machine\n",
    "learning and statistics. In machine learning and prediction based\n",
    "tasks, we are often interested in developing algorithms that are\n",
    "capable of learning patterns from given data in an automated fashion,\n",
    "and then using these learned patterns to make predictions or\n",
    "assessments of newly given data. In many cases, our primary concern\n",
    "is the quality of the predictions or assessments, and we are less\n",
    "concerned about the underlying patterns that were learned in order\n",
    "to make these predictions.\n",
    "\n",
    "In machine learning we normally use [a so-called frequentist approach](https://en.wikipedia.org/wiki/Frequentist_inference),\n",
    "where the aim is to make predictions and find correlations. We focus\n",
    "less on for example extracting a probability distribution function (PDF). The PDF can be\n",
    "used in turn to make estimations and find causations such as given $A$\n",
    "what is the likelihood of finding $B$.\n",
    "\n",
    "\n",
    "### What is a good model?\n",
    "\n",
    "In science and engineering we often end up in situations where we want to infer (or learn) a\n",
    "quantitative model $M$ for a given set of sample points $\\boldsymbol{X} \\in [x_1, x_2,\\dots x_N]$.\n",
    "\n",
    "As we will see repeatedely in these lectures, we could try to fit these data points to a model given by a\n",
    "straight line, or if we wish to be more sophisticated to a more complex\n",
    "function.\n",
    "\n",
    "The reason for inferring such a model is that it\n",
    "serves many useful purposes. On the one hand, the model can reveal information\n",
    "encoded in the data or underlying mechanisms from which the data were generated. For instance, we could discover important\n",
    "corelations that relate interesting physics interpretations.\n",
    "\n",
    "In addition, it can simplify the representation of the given data set and help\n",
    "us in making predictions about  future data samples.\n",
    "\n",
    "A first important consideration to keep in mind is that inferring the *correct* model\n",
    "for a given data set is an elusive, if not impossible, task. The fundamental difficulty\n",
    "is that if we are not specific about what we mean by a *correct* model, there\n",
    "could easily be many different models that fit the given data set *equally well*.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The central question is this: what leads us to say that a model is correct or\n",
    "optimal for a given data set? To make the model inference problem well posed, i.e.,\n",
    "to guarantee that there is a unique optimal model for the given data, we need to\n",
    "impose additional assumptions or restrictions on the class of models considered. To\n",
    "this end, we should not be looking for just any model that can describe the data.\n",
    "Instead, we should look for a **model** $M$ that is the best among a restricted class\n",
    "of models. In addition, to make the model inference problem computationally\n",
    "tractable, we need to specify how restricted the class of models needs to be. A\n",
    "common strategy is to start \n",
    "with the simplest possible class of models that is just necessary to describe the data\n",
    "or solve the problem at hand. More precisely, the model class should be rich enough\n",
    "to contain at least one model that can fit the data to a desired accuracy and yet be\n",
    "restricted enough that it is relatively simple to find the best model for the given data.\n",
    "\n",
    "Thus, the most popular strategy is to start from the\n",
    "simplest class of models and increase the complexity of the models only when the\n",
    "simpler models become inadequate. For instance, if we work with a regression problem to fit a set of sample points, one\n",
    "may first try the simplest class of models, namely linear models, followed obviously by more complex models.\n",
    "\n",
    "How to evaluate which model fits best the data is something we will come back to over and over again in these sets of lectures.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Simple linear regression model using **scikit-learn**\n",
    "\n",
    "We start with perhaps our simplest possible example, using **Scikit-Learn** to perform linear regression analysis on a data set produced by us. \n",
    "\n",
    "What follows is a simple Python code where we have defined a function\n",
    "$y$ in terms of the variable $x$. Both are defined as vectors with  $100$ entries. \n",
    "The numbers in the vector $\\boldsymbol{x}$ are given\n",
    "by random numbers generated with a uniform distribution with entries\n",
    "$x_i \\in [0,1]$ (more about probability distribution functions\n",
    "later). These values are then used to define a function $y(x)$\n",
    "(tabulated again as a vector) with a linear dependence on $x$ plus a\n",
    "random noise added via the normal distribution.\n",
    "\n",
    "\n",
    "The Numpy functions are imported used the **import numpy as np**\n",
    "statement and the random number generator for the uniform distribution\n",
    "is called using the function **np.random.rand()**, where we specificy\n",
    "that we want $100$ random variables.  Using Numpy we define\n",
    "automatically an array with the specified number of elements, $100$ in\n",
    "our case.  With the Numpy function **randn()** we can compute random\n",
    "numbers with the normal distribution (mean value $\\mu$ equal to zero and\n",
    "variance $\\sigma^2$ set to one) and produce the values of $y$ assuming a linear\n",
    "dependence as function of $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = 2x+N(0,1),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $N(0,1)$ represents random numbers generated by the normal\n",
    "distribution.  From **Scikit-Learn** we import then the\n",
    "**LinearRegression** functionality and make a prediction $\\tilde{y} =\n",
    "\\alpha + \\beta x$ using the function **fit(x,y)**. We call the set of\n",
    "data $(\\boldsymbol{x},\\boldsymbol{y})$ for our training data. The Python package\n",
    "**scikit-learn** has also a functionality which extracts the above\n",
    "fitting parameters $\\alpha$ and $\\beta$ (see below). Later we will\n",
    "distinguish between training data and test data.\n",
    "\n",
    "For plotting we use the Python package\n",
    "[matplotlib](https://matplotlib.org/) which produces publication\n",
    "quality figures. Feel free to explore the extensive\n",
    "[gallery](https://matplotlib.org/gallery/index.html) of examples. In\n",
    "this example we plot our original values of $x$ and $y$ as well as the\n",
    "prediction **ypredict** ($\\tilde{y}$), which attempts at fitting our\n",
    "data with a straight line.\n",
    "\n",
    "The Python code follows here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 384.192187 277.314375\" width=\"384.192187pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-08-27T10:21:28.802875</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 384.192187 277.314375 \n",
       "L 384.192187 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 239.758125 \n",
       "L 369.040625 239.758125 \n",
       "L 369.040625 22.318125 \n",
       "L 34.240625 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m8c492aeccf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(26.289062 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "        <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"101.200625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(93.249063 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.160625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(160.209063 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"235.120625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(227.169063 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.080625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(294.129063 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.040625\" xlink:href=\"#m8c492aeccf\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(361.089063 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- $x$ -->\n",
       "     <g transform=\"translate(198.640625 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 60.015625 54.6875 \n",
       "L 34.90625 27.875 \n",
       "L 50.296875 0 \n",
       "L 39.984375 0 \n",
       "L 28.421875 21.6875 \n",
       "L 8.296875 0 \n",
       "L -2.59375 0 \n",
       "L 24.3125 28.8125 \n",
       "L 10.015625 54.6875 \n",
       "L 20.3125 54.6875 \n",
       "L 30.8125 34.90625 \n",
       "L 49.125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-120\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"meee9d09e2c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(20.878125 243.557344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"196.270125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(20.878125 200.069344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"152.782125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(20.878125 156.581344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"109.294125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 3 -->\n",
       "      <g transform=\"translate(20.878125 113.093344)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"65.806125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(20.878125 69.605344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#meee9d09e2c\" y=\"22.318125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(20.878125 26.117344)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- $y$ -->\n",
       "     <g transform=\"translate(14.778125 134.038125)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 24.8125 -5.078125 \n",
       "Q 18.5625 -15.578125 14.625 -18.1875 \n",
       "Q 10.6875 -20.796875 4.59375 -20.796875 \n",
       "L -2.484375 -20.796875 \n",
       "L -0.984375 -13.28125 \n",
       "L 4.203125 -13.28125 \n",
       "Q 7.953125 -13.28125 10.59375 -11.234375 \n",
       "Q 13.234375 -9.1875 16.5 -3.21875 \n",
       "L 19.28125 2 \n",
       "L 7.171875 54.6875 \n",
       "L 16.703125 54.6875 \n",
       "L 25.78125 12.796875 \n",
       "L 50.875 54.6875 \n",
       "L 60.296875 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-121\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-121\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p3fc1f88037)\" d=\"M 34.240625 238.85212 \n",
       "L 369.040625 146.312225 \n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"mdd6f227edc\" style=\"stroke:#ff0000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p3fc1f88037)\">\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"244.221777\" xlink:href=\"#mdd6f227edc\" y=\"259.885597\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"160.695637\" xlink:href=\"#mdd6f227edc\" y=\"213.143128\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"126.165469\" xlink:href=\"#mdd6f227edc\" y=\"335.647439\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"236.397064\" xlink:href=\"#mdd6f227edc\" y=\"186.060037\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"37.428354\" xlink:href=\"#mdd6f227edc\" y=\"296.006878\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"359.079887\" xlink:href=\"#mdd6f227edc\" y=\"180.127239\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"287.716074\" xlink:href=\"#mdd6f227edc\" y=\"142.729337\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"312.251263\" xlink:href=\"#mdd6f227edc\" y=\"63.01972\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"219.746225\" xlink:href=\"#mdd6f227edc\" y=\"94.013763\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"129.530859\" xlink:href=\"#mdd6f227edc\" y=\"236.593625\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"169.35399\" xlink:href=\"#mdd6f227edc\" y=\"264.359281\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"247.870098\" xlink:href=\"#mdd6f227edc\" y=\"232.936844\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"249.638742\" xlink:href=\"#mdd6f227edc\" y=\"201.606545\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"76.851208\" xlink:href=\"#mdd6f227edc\" y=\"190.521134\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"156.515407\" xlink:href=\"#mdd6f227edc\" y=\"218.46626\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"268.874975\" xlink:href=\"#mdd6f227edc\" y=\"128.333965\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"135.87647\" xlink:href=\"#mdd6f227edc\" y=\"161.649737\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"219.551804\" xlink:href=\"#mdd6f227edc\" y=\"263.285372\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"88.920909\" xlink:href=\"#mdd6f227edc\" y=\"230.083483\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"105.055948\" xlink:href=\"#mdd6f227edc\" y=\"152.985647\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"304.561177\" xlink:href=\"#mdd6f227edc\" y=\"182.000591\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"264.55005\" xlink:href=\"#mdd6f227edc\" y=\"126.370022\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"66.540666\" xlink:href=\"#mdd6f227edc\" y=\"205.773479\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"159.982178\" xlink:href=\"#mdd6f227edc\" y=\"237.448493\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"318.647841\" xlink:href=\"#mdd6f227edc\" y=\"215.820424\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"228.072061\" xlink:href=\"#mdd6f227edc\" y=\"87.237138\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"87.193239\" xlink:href=\"#mdd6f227edc\" y=\"202.560061\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"265.586112\" xlink:href=\"#mdd6f227edc\" y=\"244.445362\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"267.103121\" xlink:href=\"#mdd6f227edc\" y=\"173.982272\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"233.208158\" xlink:href=\"#mdd6f227edc\" y=\"157.879099\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"205.827657\" xlink:href=\"#mdd6f227edc\" y=\"138.107887\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"82.19961\" xlink:href=\"#mdd6f227edc\" y=\"254.814904\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"209.899123\" xlink:href=\"#mdd6f227edc\" y=\"262.777669\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"180.859232\" xlink:href=\"#mdd6f227edc\" y=\"185.504752\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"229.078016\" xlink:href=\"#mdd6f227edc\" y=\"214.243936\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"175.410458\" xlink:href=\"#mdd6f227edc\" y=\"168.231928\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"367.076095\" xlink:href=\"#mdd6f227edc\" y=\"94.712172\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"251.850102\" xlink:href=\"#mdd6f227edc\" y=\"140.490274\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"97.937366\" xlink:href=\"#mdd6f227edc\" y=\"212.227046\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"131.804693\" xlink:href=\"#mdd6f227edc\" y=\"163.846856\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"107.929222\" xlink:href=\"#mdd6f227edc\" y=\"275.024257\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"248.66253\" xlink:href=\"#mdd6f227edc\" y=\"224.689059\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"81.297609\" xlink:href=\"#mdd6f227edc\" y=\"173.826776\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"268.702415\" xlink:href=\"#mdd6f227edc\" y=\"162.706103\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"362.045641\" xlink:href=\"#mdd6f227edc\" y=\"177.556023\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"170.258399\" xlink:href=\"#mdd6f227edc\" y=\"237.051287\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"190.521706\" xlink:href=\"#mdd6f227edc\" y=\"247.318904\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"225.870898\" xlink:href=\"#mdd6f227edc\" y=\"174.753933\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"110.556449\" xlink:href=\"#mdd6f227edc\" y=\"258.841267\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"66.672352\" xlink:href=\"#mdd6f227edc\" y=\"195.491748\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"348.593553\" xlink:href=\"#mdd6f227edc\" y=\"151.323325\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"149.658497\" xlink:href=\"#mdd6f227edc\" y=\"283.845202\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"308.374133\" xlink:href=\"#mdd6f227edc\" y=\"182.817495\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"104.037095\" xlink:href=\"#mdd6f227edc\" y=\"231.454451\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"282.648751\" xlink:href=\"#mdd6f227edc\" y=\"194.118228\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"196.408804\" xlink:href=\"#mdd6f227edc\" y=\"91.978177\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"325.519906\" xlink:href=\"#mdd6f227edc\" y=\"152.17709\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"300.269076\" xlink:href=\"#mdd6f227edc\" y=\"167.91712\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"207.17019\" xlink:href=\"#mdd6f227edc\" y=\"140.500069\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"119.596544\" xlink:href=\"#mdd6f227edc\" y=\"212.820837\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"70.227822\" xlink:href=\"#mdd6f227edc\" y=\"216.834691\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"182.980776\" xlink:href=\"#mdd6f227edc\" y=\"213.95288\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"257.831065\" xlink:href=\"#mdd6f227edc\" y=\"108.836305\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"191.394482\" xlink:href=\"#mdd6f227edc\" y=\"229.850682\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"324.899706\" xlink:href=\"#mdd6f227edc\" y=\"186.665027\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"332.135954\" xlink:href=\"#mdd6f227edc\" y=\"128.181774\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"100.970757\" xlink:href=\"#mdd6f227edc\" y=\"191.150507\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"246.003748\" xlink:href=\"#mdd6f227edc\" y=\"134.803007\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"183.545584\" xlink:href=\"#mdd6f227edc\" y=\"144.027934\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"113.213211\" xlink:href=\"#mdd6f227edc\" y=\"177.987597\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"300.045844\" xlink:href=\"#mdd6f227edc\" y=\"181.713961\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"81.583439\" xlink:href=\"#mdd6f227edc\" y=\"235.944864\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"154.373589\" xlink:href=\"#mdd6f227edc\" y=\"234.979141\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"41.857566\" xlink:href=\"#mdd6f227edc\" y=\"339.952225\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"100.682703\" xlink:href=\"#mdd6f227edc\" y=\"213.211783\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"127.15173\" xlink:href=\"#mdd6f227edc\" y=\"168.601444\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"239.008279\" xlink:href=\"#mdd6f227edc\" y=\"241.846505\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"127.376844\" xlink:href=\"#mdd6f227edc\" y=\"145.426682\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"220.145847\" xlink:href=\"#mdd6f227edc\" y=\"206.488788\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"65.388949\" xlink:href=\"#mdd6f227edc\" y=\"240.981437\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.599034\" xlink:href=\"#mdd6f227edc\" y=\"195.344305\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"83.909323\" xlink:href=\"#mdd6f227edc\" y=\"187.44445\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"189.564284\" xlink:href=\"#mdd6f227edc\" y=\"171.713391\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"366.805897\" xlink:href=\"#mdd6f227edc\" y=\"173.741673\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"218.609514\" xlink:href=\"#mdd6f227edc\" y=\"169.275291\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"256.671481\" xlink:href=\"#mdd6f227edc\" y=\"236.376396\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"313.784575\" xlink:href=\"#mdd6f227edc\" y=\"146.872439\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"344.292965\" xlink:href=\"#mdd6f227edc\" y=\"147.672581\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"228.568838\" xlink:href=\"#mdd6f227edc\" y=\"195.285855\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"166.602239\" xlink:href=\"#mdd6f227edc\" y=\"186.053579\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"310.864477\" xlink:href=\"#mdd6f227edc\" y=\"216.616783\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"352.152144\" xlink:href=\"#mdd6f227edc\" y=\"160.401894\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"313.286109\" xlink:href=\"#mdd6f227edc\" y=\"108.915762\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"362.428282\" xlink:href=\"#mdd6f227edc\" y=\"155.513989\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"250.103691\" xlink:href=\"#mdd6f227edc\" y=\"150.999466\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"82.398381\" xlink:href=\"#mdd6f227edc\" y=\"251.082224\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"182.597088\" xlink:href=\"#mdd6f227edc\" y=\"259.695076\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"95.185262\" xlink:href=\"#mdd6f227edc\" y=\"211.72087\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"158.329456\" xlink:href=\"#mdd6f227edc\" y=\"194.580917\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"175.209775\" xlink:href=\"#mdd6f227edc\" y=\"138.391085\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 239.758125 \n",
       "L 34.240625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 369.040625 239.758125 \n",
       "L 369.040625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 239.758125 \n",
       "L 369.040625 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 22.318125 \n",
       "L 369.040625 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Simple Linear Regression -->\n",
       "    <g transform=\"translate(125.875625 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "      <path d=\"M 44.390625 34.1875 \n",
       "Q 47.5625 33.109375 50.5625 29.59375 \n",
       "Q 53.5625 26.078125 56.59375 19.921875 \n",
       "L 66.609375 0 \n",
       "L 56 0 \n",
       "L 46.6875 18.703125 \n",
       "Q 43.0625 26.03125 39.671875 28.421875 \n",
       "Q 36.28125 30.8125 30.421875 30.8125 \n",
       "L 19.671875 30.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.578125 72.90625 50.734375 67.671875 \n",
       "Q 56.890625 62.453125 56.890625 51.90625 \n",
       "Q 56.890625 45.015625 53.6875 40.46875 \n",
       "Q 50.484375 35.9375 44.390625 34.1875 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 38.921875 \n",
       "L 32.078125 38.921875 \n",
       "Q 39.203125 38.921875 42.84375 42.21875 \n",
       "Q 46.484375 45.515625 46.484375 51.90625 \n",
       "Q 46.484375 58.296875 42.84375 61.546875 \n",
       "Q 39.203125 64.796875 32.078125 64.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-82\"/>\n",
       "      <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-103\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-83\"/>\n",
       "     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"91.259766\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"188.671875\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "     <use x=\"252.148438\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"279.931641\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"341.455078\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"373.242188\" xlink:href=\"#DejaVuSans-76\"/>\n",
       "     <use x=\"428.955078\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"456.738281\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"520.117188\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"581.640625\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"642.919922\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"684.033203\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"715.820312\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "     <use x=\"780.802734\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"842.326172\" xlink:href=\"#DejaVuSans-103\"/>\n",
       "     <use x=\"905.802734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"944.666016\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"1006.189453\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"1058.289062\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"1110.388672\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"1138.171875\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"1199.353516\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p3fc1f88037\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"34.240625\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Importing various packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = np.random.rand(100,1)\n",
    "y = 2*x+np.random.randn(100,1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x,y)\n",
    "xnew = np.array([[0],[1]])\n",
    "ypredict = linreg.predict(xnew)\n",
    "\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,1.0,0, 5.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Simple Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example serves several aims. It allows us to demonstrate several\n",
    "aspects of data analysis and later machine learning algorithms. The\n",
    "immediate visualization shows that our linear fit is not\n",
    "impressive. It goes through the data points, but there are many\n",
    "outliers which are not reproduced by our linear regression.  We could\n",
    "now play around with this small program and change for example the\n",
    "factor in front of $x$ and the normal distribution.  Try to change the\n",
    "function $y$ to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = 10x+0.01 \\times N(0,1),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $x$ is defined as before.  Does the fit look better? Indeed, by\n",
    "reducing the role of the noise given by the normal distribution we see immediately that\n",
    "our linear prediction seemingly reproduces better the training\n",
    "set. However, this testing 'by the eye' is obviouly not satisfactory in the\n",
    "long run. Here we have only defined the training data and our model, and \n",
    "have not discussed a more rigorous approach to the **cost** function.\n",
    "\n",
    "We need more rigorous criteria in defining whether we have succeeded or\n",
    "not in modeling our training data.  You will be surprised to see that\n",
    "many scientists seldomly venture beyond this 'by the eye' approach. A\n",
    "standard approach for the *cost* function is the so-called $\\chi^2$\n",
    "function (a variant of the mean-squared error (MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2 = \\frac{1}{n}\n",
    "\\sum_{i=0}^{n-1}\\frac{(y_i-\\tilde{y}_i)^2}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\sigma_i^2$ is the variance (to be defined later) of the entry\n",
    "$y_i$.  We may not know the explicit value of $\\sigma_i^2$, it serves\n",
    "however the aim of scaling the equations and make the cost function\n",
    "dimensionless.  \n",
    "\n",
    "Minimizing the cost function is a central aspect of\n",
    "our discussions to come. Finding its minima as function of the model\n",
    "parameters ($\\alpha$ and $\\beta$ in our case) will be a recurring\n",
    "theme in these series of lectures. Essentially all machine learning\n",
    "algorithms we will discuss center around the minimization of the\n",
    "chosen cost function. This depends in turn on our specific\n",
    "model for describing the data, a typical situation in supervised\n",
    "learning. Automatizing the search for the minima of the cost function is a\n",
    "central ingredient in all algorithms. Typical methods which are\n",
    "employed are various variants of **gradient** methods. These will be\n",
    "discussed in more detail later. Again, you'll be surprised to hear that\n",
    "many practitioners minimize the above function ''by the eye', popularly dubbed as \n",
    "'chi by the eye'. That is, change a parameter and see (visually and numerically) that \n",
    "the  $\\chi^2$ function becomes smaller. \n",
    "\n",
    "There are many ways to define the cost function. A simpler approach is to look at the relative difference between the training data and the predicted data, that is we define \n",
    "the relative error (why would we prefer the MSE instead of the relative error?) as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\epsilon_{\\mathrm{relative}}= \\frac{\\vert \\boldsymbol{y} -\\boldsymbol{\\tilde{y}}\\vert}{\\vert \\boldsymbol{y}\\vert}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared cost function results in an arithmetic mean-unbiased\n",
    "estimator, and the absolute-value cost function results in a\n",
    "median-unbiased estimator (in the one-dimensional case, and a\n",
    "geometric median-unbiased estimator for the multi-dimensional\n",
    "case). The squared cost function has the disadvantage that it has the tendency\n",
    "to be dominated by outliers.\n",
    "\n",
    "We can modify easily the above Python code and plot the relative error instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 393.732813 277.314375\" width=\"393.732813pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-08-27T10:21:39.690958</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 393.732813 277.314375 \n",
       "L 393.732813 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 378.58125 239.758125 \n",
       "L 378.58125 22.318125 \n",
       "L 43.78125 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m7283f54820\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(35.829688 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "        <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.74125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(102.789688 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.70125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(169.749688 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"244.66125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(236.709688 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"311.62125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(303.669688 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.58125\" xlink:href=\"#m7283f54820\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(370.629687 254.356562)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- $x$ -->\n",
       "     <g transform=\"translate(208.18125 268.034687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 60.015625 54.6875 \n",
       "L 34.90625 27.875 \n",
       "L 50.296875 0 \n",
       "L 39.984375 0 \n",
       "L 28.421875 21.6875 \n",
       "L 8.296875 0 \n",
       "L -2.59375 0 \n",
       "L 24.3125 28.8125 \n",
       "L 10.015625 54.6875 \n",
       "L 20.3125 54.6875 \n",
       "L 30.8125 34.90625 \n",
       "L 49.125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-120\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.3125)\" xlink:href=\"#DejaVuSans-Oblique-120\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m7c7cf5ea2d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(20.878125 243.557344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"196.270125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.1 -->\n",
       "      <g transform=\"translate(20.878125 200.069344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"152.782125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(20.878125 156.581344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"109.294125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.3 -->\n",
       "      <g transform=\"translate(20.878125 113.093344)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"65.806125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(20.878125 69.605344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7c7cf5ea2d\" y=\"22.318125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.5 -->\n",
       "      <g transform=\"translate(20.878125 26.117344)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- $\\epsilon_{\\mathrm{relative}}$ -->\n",
       "     <g transform=\"translate(14.798438 147.188125)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path d=\"M 19.734375 29.5 \n",
       "Q 14.453125 30.671875 12.15625 33.84375 \n",
       "Q 10.453125 36.078125 10.453125 39.109375 \n",
       "Q 10.453125 47.40625 18.359375 52.25 \n",
       "Q 24.609375 56.0625 34.1875 56.0625 \n",
       "Q 37.890625 56.0625 41.9375 55.46875 \n",
       "Q 46 54.890625 50.53125 53.71875 \n",
       "L 48.96875 45.5625 \n",
       "Q 44.484375 46.96875 40.71875 47.609375 \n",
       "Q 36.859375 48.25 33.40625 48.25 \n",
       "Q 27.59375 48.25 23.78125 46 \n",
       "Q 19.1875 43.3125 19.1875 39.40625 \n",
       "Q 19.1875 36.8125 21.578125 35.015625 \n",
       "Q 24.421875 32.859375 30.078125 32.859375 \n",
       "L 37.640625 32.859375 \n",
       "L 36.234375 25.4375 \n",
       "L 29 25.4375 \n",
       "Q 22.265625 25.4375 18.3125 22.953125 \n",
       "Q 12.9375 19.578125 12.9375 14.3125 \n",
       "Q 12.9375 10.984375 15.828125 8.796875 \n",
       "Q 19.4375 6.0625 26.8125 6.0625 \n",
       "Q 31.34375 6.0625 35.6875 6.9375 \n",
       "Q 40.046875 7.859375 43.84375 9.671875 \n",
       "L 42.1875 1.3125 \n",
       "Q 37.546875 -0.046875 33.296875 -0.734375 \n",
       "Q 29.046875 -1.421875 25.140625 -1.421875 \n",
       "Q 13.53125 -1.421875 8.0625 3.03125 \n",
       "Q 3.90625 6.453125 3.90625 12.203125 \n",
       "Q 3.90625 19.96875 9.375 24.75 \n",
       "Q 13.421875 28.328125 19.734375 29.5 \n",
       "z\n",
       "\" id=\"DejaVuSans-Oblique-949\"/>\n",
       "       <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "       <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "       <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "       <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "       <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "       <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      </defs>\n",
       "      <use transform=\"translate(0 0.9375)\" xlink:href=\"#DejaVuSans-Oblique-949\"/>\n",
       "      <use transform=\"translate(54.052734 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use transform=\"translate(82.832031 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use transform=\"translate(125.898438 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use transform=\"translate(145.34668 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use transform=\"translate(188.242188 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use transform=\"translate(215.688477 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use transform=\"translate(235.136719 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use transform=\"translate(276.5625 -15.46875)scale(0.7)\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"mcdb0229972\" style=\"stroke:#ff0000;\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pd93dfe1925)\">\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"323.411291\" xlink:href=\"#mcdb0229972\" y=\"237.172435\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"256.372227\" xlink:href=\"#mcdb0229972\" y=\"239.606305\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"179.373311\" xlink:href=\"#mcdb0229972\" y=\"239.224497\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"55.777756\" xlink:href=\"#mcdb0229972\" y=\"239.074224\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"278.863231\" xlink:href=\"#mcdb0229972\" y=\"237.58142\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"173.991382\" xlink:href=\"#mcdb0229972\" y=\"236.77869\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"106.870645\" xlink:href=\"#mcdb0229972\" y=\"239.243244\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"101.779732\" xlink:href=\"#mcdb0229972\" y=\"234.870285\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"167.086369\" xlink:href=\"#mcdb0229972\" y=\"238.150762\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"203.506755\" xlink:href=\"#mcdb0229972\" y=\"237.134049\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"327.641734\" xlink:href=\"#mcdb0229972\" y=\"239.166787\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"244.860448\" xlink:href=\"#mcdb0229972\" y=\"239.637837\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.796558\" xlink:href=\"#mcdb0229972\" y=\"239.713224\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"90.258054\" xlink:href=\"#mcdb0229972\" y=\"229.767309\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"97.409074\" xlink:href=\"#mcdb0229972\" y=\"239.29896\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"267.132802\" xlink:href=\"#mcdb0229972\" y=\"239.685106\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"267.285803\" xlink:href=\"#mcdb0229972\" y=\"238.122645\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"297.453143\" xlink:href=\"#mcdb0229972\" y=\"238.226437\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"44.47478\" xlink:href=\"#mcdb0229972\" y=\"46.290261\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"351.181835\" xlink:href=\"#mcdb0229972\" y=\"238.578511\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"143.033925\" xlink:href=\"#mcdb0229972\" y=\"238.795707\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"176.303594\" xlink:href=\"#mcdb0229972\" y=\"237.925443\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"148.336012\" xlink:href=\"#mcdb0229972\" y=\"235.741528\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"155.482679\" xlink:href=\"#mcdb0229972\" y=\"238.385329\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"304.725683\" xlink:href=\"#mcdb0229972\" y=\"238.265583\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"333.851086\" xlink:href=\"#mcdb0229972\" y=\"239.195664\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"299.711209\" xlink:href=\"#mcdb0229972\" y=\"238.467938\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"269.33295\" xlink:href=\"#mcdb0229972\" y=\"239.208188\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"339.664433\" xlink:href=\"#mcdb0229972\" y=\"238.465474\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"362.958266\" xlink:href=\"#mcdb0229972\" y=\"239.688185\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"44.94557\" xlink:href=\"#mcdb0229972\" y=\"124.698134\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"286.278383\" xlink:href=\"#mcdb0229972\" y=\"238.858024\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"130.927555\" xlink:href=\"#mcdb0229972\" y=\"239.34465\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"284.982446\" xlink:href=\"#mcdb0229972\" y=\"237.510993\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"115.543589\" xlink:href=\"#mcdb0229972\" y=\"238.615989\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"58.503139\" xlink:href=\"#mcdb0229972\" y=\"223.408044\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"75.40798\" xlink:href=\"#mcdb0229972\" y=\"234.346855\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"79.225684\" xlink:href=\"#mcdb0229972\" y=\"233.148506\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"343.701533\" xlink:href=\"#mcdb0229972\" y=\"239.463532\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"69.952342\" xlink:href=\"#mcdb0229972\" y=\"234.152488\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"273.749295\" xlink:href=\"#mcdb0229972\" y=\"237.782821\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"351.516365\" xlink:href=\"#mcdb0229972\" y=\"238.536106\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"254.803584\" xlink:href=\"#mcdb0229972\" y=\"238.259871\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"44.893528\" xlink:href=\"#mcdb0229972\" y=\"148.328132\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"70.406184\" xlink:href=\"#mcdb0229972\" y=\"232.960818\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"61.504423\" xlink:href=\"#mcdb0229972\" y=\"227.260807\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"132.591788\" xlink:href=\"#mcdb0229972\" y=\"237.0639\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"278.638022\" xlink:href=\"#mcdb0229972\" y=\"237.781577\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"258.355013\" xlink:href=\"#mcdb0229972\" y=\"239.287037\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"377.239521\" xlink:href=\"#mcdb0229972\" y=\"239.060708\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"105.733262\" xlink:href=\"#mcdb0229972\" y=\"238.477506\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"97.094828\" xlink:href=\"#mcdb0229972\" y=\"233.440856\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"241.049315\" xlink:href=\"#mcdb0229972\" y=\"237.7995\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"78.621564\" xlink:href=\"#mcdb0229972\" y=\"234.213375\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"374.258338\" xlink:href=\"#mcdb0229972\" y=\"238.994522\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"209.043368\" xlink:href=\"#mcdb0229972\" y=\"239.750828\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"282.099943\" xlink:href=\"#mcdb0229972\" y=\"238.116171\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"59.478094\" xlink:href=\"#mcdb0229972\" y=\"223.273578\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"206.711775\" xlink:href=\"#mcdb0229972\" y=\"239.222519\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"67.915849\" xlink:href=\"#mcdb0229972\" y=\"225.594794\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"237.271601\" xlink:href=\"#mcdb0229972\" y=\"239.390533\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"338.566846\" xlink:href=\"#mcdb0229972\" y=\"239.713123\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"341.657184\" xlink:href=\"#mcdb0229972\" y=\"238.748633\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"252.176915\" xlink:href=\"#mcdb0229972\" y=\"237.144143\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"128.213719\" xlink:href=\"#mcdb0229972\" y=\"239.614077\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"120.450975\" xlink:href=\"#mcdb0229972\" y=\"239.487008\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"99.658186\" xlink:href=\"#mcdb0229972\" y=\"233.249183\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"187.430194\" xlink:href=\"#mcdb0229972\" y=\"237.418916\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"236.598203\" xlink:href=\"#mcdb0229972\" y=\"237.949002\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"362.010346\" xlink:href=\"#mcdb0229972\" y=\"238.660099\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"127.357575\" xlink:href=\"#mcdb0229972\" y=\"238.352877\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"322.150305\" xlink:href=\"#mcdb0229972\" y=\"239.72048\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"286.198555\" xlink:href=\"#mcdb0229972\" y=\"239.560893\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"275.330369\" xlink:href=\"#mcdb0229972\" y=\"237.326145\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"159.047608\" xlink:href=\"#mcdb0229972\" y=\"236.589874\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"239.771733\" xlink:href=\"#mcdb0229972\" y=\"238.051938\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"154.727025\" xlink:href=\"#mcdb0229972\" y=\"238.327359\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"355.241023\" xlink:href=\"#mcdb0229972\" y=\"239.395041\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"205.726449\" xlink:href=\"#mcdb0229972\" y=\"239.162712\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"317.632908\" xlink:href=\"#mcdb0229972\" y=\"238.578294\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"151.348999\" xlink:href=\"#mcdb0229972\" y=\"239.532744\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"364.938212\" xlink:href=\"#mcdb0229972\" y=\"238.646963\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"326.049847\" xlink:href=\"#mcdb0229972\" y=\"239.059859\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"60.706071\" xlink:href=\"#mcdb0229972\" y=\"233.723476\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"134.884033\" xlink:href=\"#mcdb0229972\" y=\"237.668638\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"67.922421\" xlink:href=\"#mcdb0229972\" y=\"235.196053\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"271.365518\" xlink:href=\"#mcdb0229972\" y=\"239.222402\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"219.889441\" xlink:href=\"#mcdb0229972\" y=\"238.842806\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"319.202319\" xlink:href=\"#mcdb0229972\" y=\"239.509182\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"262.692485\" xlink:href=\"#mcdb0229972\" y=\"239.653509\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"122.049425\" xlink:href=\"#mcdb0229972\" y=\"239.277978\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"283.733589\" xlink:href=\"#mcdb0229972\" y=\"237.112289\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"57.221011\" xlink:href=\"#mcdb0229972\" y=\"231.229516\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"204.934882\" xlink:href=\"#mcdb0229972\" y=\"237.629656\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"370.338615\" xlink:href=\"#mcdb0229972\" y=\"239.286659\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"181.650879\" xlink:href=\"#mcdb0229972\" y=\"238.605436\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"220.391088\" xlink:href=\"#mcdb0229972\" y=\"238.376899\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"223.165028\" xlink:href=\"#mcdb0229972\" y=\"239.350866\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"119.043459\" xlink:href=\"#mcdb0229972\" y=\"239.003791\"/>\n",
       "     <use style=\"fill:#ff0000;stroke:#ff0000;\" x=\"377.007112\" xlink:href=\"#mcdb0229972\" y=\"238.584006\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 43.78125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 239.758125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 378.58125 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 22.318125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Relative error -->\n",
       "    <g transform=\"translate(170.554688 16.318125)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 44.390625 34.1875 \n",
       "Q 47.5625 33.109375 50.5625 29.59375 \n",
       "Q 53.5625 26.078125 56.59375 19.921875 \n",
       "L 66.609375 0 \n",
       "L 56 0 \n",
       "L 46.6875 18.703125 \n",
       "Q 43.0625 26.03125 39.671875 28.421875 \n",
       "Q 36.28125 30.8125 30.421875 30.8125 \n",
       "L 19.671875 30.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.578125 72.90625 50.734375 67.671875 \n",
       "Q 56.890625 62.453125 56.890625 51.90625 \n",
       "Q 56.890625 45.015625 53.6875 40.46875 \n",
       "Q 50.484375 35.9375 44.390625 34.1875 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 38.921875 \n",
       "L 32.078125 38.921875 \n",
       "Q 39.203125 38.921875 42.84375 42.21875 \n",
       "Q 46.484375 45.515625 46.484375 51.90625 \n",
       "Q 46.484375 58.296875 42.84375 61.546875 \n",
       "Q 39.203125 64.796875 32.078125 64.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-82\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-82\"/>\n",
       "     <use x=\"64.982422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"126.505859\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"154.289062\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"215.568359\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"254.777344\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"282.560547\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "     <use x=\"341.740234\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"403.263672\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"435.050781\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"496.574219\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"535.9375\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"574.800781\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"635.982422\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd93dfe1925\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = np.random.rand(100,1)\n",
    "y = 5*x+0.01*np.random.randn(100,1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x,y)\n",
    "ypredict = linreg.predict(x)\n",
    "\n",
    "plt.plot(x, np.abs(ypredict-y)/abs(y), \"ro\")\n",
    "plt.axis([0,1.0,0.0, 0.5])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$\\epsilon_{\\mathrm{relative}}$')\n",
    "plt.title(r'Relative error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the parameter in front of the normal distribution, we may\n",
    "have a small or larger relative error. Try to play around with\n",
    "different training data sets and study (graphically) the value of the\n",
    "relative error.\n",
    "\n",
    "As mentioned above, **Scikit-Learn** has an impressive functionality.\n",
    "We can for example extract the values of $\\alpha$ and $\\beta$ and\n",
    "their error estimates, or the variance and standard deviation and many\n",
    "other properties from the statistical data analysis. \n",
    "\n",
    "Here we show an\n",
    "example of the functionality of **Scikit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "x = np.random.rand(100,1)\n",
    "y = 2.0+ 5*x+0.5*np.random.randn(100,1)\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(x,y)\n",
    "ypredict = linreg.predict(x)\n",
    "print('The intercept alpha: \\n', linreg.intercept_)\n",
    "print('Coefficient beta : \\n', linreg.coef_)\n",
    "# The mean squared error                               \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y, ypredict))\n",
    "# Explained variance score: 1 is perfect prediction                                 \n",
    "print('Variance score: %.2f' % r2_score(y, ypredict))\n",
    "# Mean squared log error                                                        \n",
    "print('Mean squared log error: %.2f' % mean_squared_log_error(y, ypredict) )\n",
    "# Mean absolute error                                                           \n",
    "print('Mean absolute error: %.2f' % mean_absolute_error(y, ypredict))\n",
    "plt.plot(x, ypredict, \"r-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0.0,1.0,1.5, 7.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Linear Regression fit ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **coef** gives us the parameter $\\beta$ of our fit while **intercept** yields \n",
    "$\\alpha$. Depending on the constant in front of the normal distribution, we get values near or far from $alpha =2$ and $\\beta =5$. Try to play around with different parameters in front of the normal distribution. The function **meansquarederror** gives us the mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE(\\boldsymbol{y},\\boldsymbol{\\tilde{y}}) = \\frac{1}{n}\n",
    "\\sum_{i=0}^{n-1}(y_i-\\tilde{y}_i)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the value, the better the fit. Ideally we would like to\n",
    "have an MSE equal zero.  The attentive reader has probably recognized\n",
    "this function as being similar to the $\\chi^2$ function defined above.\n",
    "\n",
    "The **r2score** function computes $R^2$, the coefficient of\n",
    "determination. It provides a measure of how well future samples are\n",
    "likely to be predicted by the model. Best possible score is 1.0 and it\n",
    "can be negative (because the model can be arbitrarily worse). A\n",
    "constant model that always predicts the expected value of $\\boldsymbol{y}$,\n",
    "disregarding the input features, would get a $R^2$ score of $0.0$.\n",
    "\n",
    "If $\\tilde{\\boldsymbol{y}}_i$ is the predicted value of the $i-th$ sample and $y_i$ is the corresponding true value, then the score $R^2$ is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R^2(\\boldsymbol{y}, \\tilde{\\boldsymbol{y}}) = 1 - \\frac{\\sum_{i=0}^{n - 1} (y_i - \\tilde{y}_i)^2}{\\sum_{i=0}^{n - 1} (y_i - \\bar{y})^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have defined the mean value  of $\\boldsymbol{y}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{y} =  \\frac{1}{n} \\sum_{i=0}^{n - 1} y_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another quantity taht we will meet again in our discussions of regression analysis is \n",
    " the mean absolute error (MAE), a risk metric corresponding to the expected value of the absolute error loss or what we call the $l1$-norm loss. In our discussion above we presented the relative error.\n",
    "The MAE is defined as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MAE}(\\boldsymbol{y}, \\boldsymbol{\\tilde{y}}) = \\frac{1}{n} \\sum_{i=0}^{n-1} \\left| y_i - \\tilde{y}_i \\right|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the \n",
    "squared logarithmic (quadratic) error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{MSLE}(\\boldsymbol{y}, \\boldsymbol{\\tilde{y}}) = \\frac{1}{n} \\sum_{i=0}^{n - 1} (\\log_e (1 + y_i) - \\log_e (1 + \\tilde{y}_i) )^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\log_e (x)$ stands for the natural logarithm of $x$. This error\n",
    "estimate is best to use when targets having exponential growth, such\n",
    "as population counts, average sales of a commodity over a span of\n",
    "years etc. \n",
    "\n",
    "\n",
    "Finally, another cost function is the Huber cost function used in robust regression.\n",
    "\n",
    "The rationale behind this possible cost function is its reduced\n",
    "sensitivity to outliers in the data set. In our discussions on\n",
    "dimensionality reduction and normalization of data we will meet other\n",
    "ways of dealing with outliers.\n",
    "\n",
    "The Huber cost function is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H_{\\delta}(\\boldsymbol{a})=\\left\\{\\begin{array}{cc}\\frac{1}{2} \\boldsymbol{a}^{2}& \\text{for }|\\boldsymbol{a}|\\leq \\delta\\\\ \\delta (|\\b\\\n",
    "m{a}|-\\frac{1}{2}\\delta ),&\\text{otherwise}.\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\boldsymbol{a}=\\boldsymbol{y} - \\boldsymbol{\\tilde{y}}$.\n",
    "\n",
    "\n",
    "We will discuss in more\n",
    "detail these and other functions in the various lectures.  We conclude this part with another example. Instead of \n",
    "a linear $x$-dependence we study now a cubic polynomial and use the polynomial regression analysis tools of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x=np.linspace(0.02,0.98,200)\n",
    "noise = np.asarray(random.sample((range(200)),200))\n",
    "y=x**3*noise\n",
    "yn=x**3*100\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "X = poly3.fit_transform(x[:,np.newaxis])\n",
    "clf3 = LinearRegression()\n",
    "clf3.fit(X,y)\n",
    "\n",
    "Xplot=poly3.fit_transform(x[:,np.newaxis])\n",
    "poly3_plot=plt.plot(x, clf3.predict(Xplot), label='Cubic Fit')\n",
    "plt.plot(x,yn, color='red', label=\"True Cubic\")\n",
    "plt.scatter(x, y, label='Data', color='orange', s=15)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def error(a):\n",
    "    for i in y:\n",
    "        err=(y-yn)/yn\n",
    "    return abs(np.sum(err))/len(err)\n",
    "\n",
    "print (error(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now dive into  nuclear physics and remind ourselves briefly about some basic features about binding\n",
    "energies.  A basic quantity which can be measured for the ground\n",
    "states of nuclei is the atomic mass $M(N, Z)$ of the neutral atom with\n",
    "atomic mass number $A$ and charge $Z$. The number of neutrons is $N$. There are indeed several sophisticated experiments worldwide which allow us to measure this quantity to high precision (parts per million even). \n",
    "\n",
    "Atomic masses are usually tabulated in terms of the mass excess defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Delta M(N, Z) =  M(N, Z) - uA,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $u$ is the Atomic Mass Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u = M(^{12}\\mathrm{C})/12 = 931.4940954(57) \\hspace{0.1cm} \\mathrm{MeV}/c^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nucleon masses are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "m_p =  1.00727646693(9)u,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "m_n = 939.56536(8)\\hspace{0.1cm} \\mathrm{MeV}/c^2 = 1.0086649156(6)u.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [2016 mass evaluation of by W.J.Huang, G.Audi, M.Wang, F.G.Kondev, S.Naimi and X.Xu](http://nuclearmasses.org/resources_folder/Wang_2017_Chinese_Phys_C_41_030003.pdf)\n",
    "there are data on masses and decays of 3437 nuclei.\n",
    "\n",
    "The nuclear binding energy is defined as the energy required to break\n",
    "up a given nucleus into its constituent parts of $N$ neutrons and $Z$\n",
    "protons. In terms of the atomic masses $M(N, Z)$ the binding energy is\n",
    "defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "BE(N, Z) = ZM_H c^2 + Nm_n c^2 - M(N, Z)c^2 ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $M_H$ is the mass of the hydrogen atom and $m_n$ is the mass of the neutron.\n",
    "In terms of the mass excess the binding energy is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "BE(N, Z) = Z\\Delta_H c^2 + N\\Delta_n c^2 -\\Delta(N, Z)c^2 ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\Delta_H c^2 = 7.2890$ MeV and $\\Delta_n c^2 = 8.0713$ MeV.\n",
    "\n",
    "\n",
    "A popular and physically intuitive model which can be used to parametrize \n",
    "the experimental binding energies as function of $A$, is the so-called \n",
    "**liquid drop model**. The ansatz is based on the following expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "BE(N,Z) = a_1A-a_2A^{2/3}-a_3\\frac{Z^2}{A^{1/3}}-a_4\\frac{(N-Z)^2}{A},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $A$ stands for the number of nucleons and the $a_i$s are parameters which are determined by a fit \n",
    "to the experimental data.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To arrive at the above expression we have assumed that we can make the following assumptions:\n",
    "\n",
    " * There is a volume term $a_1A$ proportional with the number of nucleons (the energy is also an extensive quantity). When an assembly of nucleons of the same size is packed together into the smallest volume, each interior nucleon has a certain number of other nucleons in contact with it. This contribution is proportional to the volume.\n",
    "\n",
    " * There is a surface energy term $a_2A^{2/3}$. The assumption here is that a nucleon at the surface of a nucleus interacts with fewer other nucleons than one in the interior of the nucleus and hence its binding energy is less. This surface energy term takes that into account and is therefore negative and is proportional to the surface area.\n",
    "\n",
    " * There is a Coulomb energy term $a_3\\frac{Z^2}{A^{1/3}}$. The electric repulsion between each pair of protons in a nucleus yields less binding. \n",
    "\n",
    " * There is an asymmetry term $a_4\\frac{(N-Z)^2}{A}$. This term is associated with the Pauli exclusion principle and reflects the fact that the proton-neutron interaction is more attractive on the average than the neutron-neutron and proton-proton interactions.\n",
    "\n",
    "We could also add a so-called pairing term, which is a correction term that\n",
    "arises from the tendency of proton pairs and neutron pairs to\n",
    "occur. An even number of particles is more stable than an odd number. \n",
    "\n",
    "\n",
    "### Organizing our data\n",
    "\n",
    "Let us start with reading and organizing our data. \n",
    "We start with the compilation of masses and binding energies from 2016.\n",
    "After having downloaded this file to our own computer, we are now ready to read the file and start structuring our data.\n",
    "\n",
    "\n",
    "We start with preparing folders for storing our calculations and the data file over masses and binding energies. We import also various modules that we will find useful in order to present various Machine Learning methods. Here we focus mainly on the functionality of **scikit-learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "infile = open(data_path(\"MassEval2016.dat\"),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, we define also a function for making our plots. You can obviously avoid this and simply set up various **matplotlib** commands every time you need them. You may however find it convenient to collect all such commands in one function and simply call this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plt, mpl\n",
    "plt.style.use('seaborn')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "def MakePlot(x,y, styles, labels, axlabels):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(len(x)):\n",
    "        plt.plot(x[i], y[i], styles[i], label = labels[i])\n",
    "        plt.xlabel(axlabels[0])\n",
    "        plt.ylabel(axlabels[1])\n",
    "    plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to read the data on experimental binding energies and\n",
    "reorganize them as functions of the mass number $A$, the number of\n",
    "protons $Z$ and neutrons $N$ using **pandas**.  Before we do this it is\n",
    "always useful (unless you have a binary file or other types of compressed\n",
    "data) to actually open the file and simply take a look at it!\n",
    "\n",
    "\n",
    "In particular, the program that outputs the final nuclear masses is written in Fortran with a specific format. It means that we need to figure out the format and which columns contain the data we are interested in. Pandas comes with a function that reads formatted output. After having admired the file, we are now ready to start massaging it with **pandas**. The file begins with some basic format information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                                                                                                         \n",
    "This is taken from the data file of the mass 2016 evaluation.                                                               \n",
    "All files are 3436 lines long with 124 character per line.                                                                  \n",
    "       Headers are 39 lines long.                                                                                           \n",
    "   col 1     :  Fortran character control: 1 = page feed  0 = line feed                                                     \n",
    "   format    :  a1,i3,i5,i5,i5,1x,a3,a4,1x,f13.5,f11.5,f11.3,f9.3,1x,a2,f11.3,f9.3,1x,i3,1x,f12.5,f11.5                     \n",
    "   These formats are reflected in the pandas widths variable below, see the statement                                       \n",
    "   widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),                                                            \n",
    "   Pandas has also a variable header, with length 39 in this case.                                                          \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are interested in are in columns 2, 3, 4 and 11, giving us\n",
    "the number of neutrons, protons, mass numbers and binding energies,\n",
    "respectively. We add also for the sake of completeness the element name. The data are in fixed-width formatted lines and we will\n",
    "covert them into the **pandas** DataFrame structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the experimental data with Pandas\n",
    "Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=39,\n",
    "              index_col=False)\n",
    "\n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now read in the data, grouped them according to the variables we are interested in. \n",
    "We see how easy it is to reorganize the data using **pandas**. If we\n",
    "were to do these operations in C/C++ or Fortran, we would have had to\n",
    "write various functions/subroutines which perform the above\n",
    "reorganizations for us.  Having reorganized the data, we can now start\n",
    "to make some simple fits using both the functionalities in **numpy** and\n",
    "**Scikit-Learn** afterwards. \n",
    "\n",
    "Now we define five variables which contain\n",
    "the number of nucleons $A$, the number of protons $Z$ and the number of neutrons $N$, the element name and finally the energies themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Masses['A']\n",
    "Z = Masses['Z']\n",
    "N = Masses['N']\n",
    "Element = Masses['Element']\n",
    "Energies = Masses['Ebinding']\n",
    "print(Masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step, and we will define this mathematically later, is to set up the so-called **design matrix**. We will throughout call this matrix $\\boldsymbol{X}$.\n",
    "It has dimensionality $p\\times n$, where $n$ is the number of data points and $p$ are the so-called predictors. In our case here they are given by the number of polynomials in $A$ we wish to include in the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we set up the design matrix X\n",
    "X = np.zeros((len(A),5))\n",
    "X[:,0] = 1\n",
    "X[:,1] = A\n",
    "X[:,2] = A**(2.0/3.0)\n",
    "X[:,3] = A**(-1.0/3.0)\n",
    "X[:,4] = A**(-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **scikitlearn** we are now ready to use linear regression and fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = skl.LinearRegression().fit(X, Energies)\n",
    "fity = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty simple!  \n",
    "Now we can print measures of how our fit is doing, the coefficients from the fits and plot the final fit together with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error                               \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Energies, fity))\n",
    "# Explained variance score: 1 is perfect prediction                                 \n",
    "print('Variance score: %.2f' % r2_score(Energies, fity))\n",
    "# Mean absolute error                                                           \n",
    "print('Mean absolute error: %.2f' % mean_absolute_error(Energies, fity))\n",
    "print(clf.coef_, clf.intercept_)\n",
    "\n",
    "Masses['Eapprox']  = fity\n",
    "# Generate a plot comparing the experimental with the fitted values values.\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$A = N + Z$')\n",
    "ax.set_ylabel(r'$E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "ax.plot(Masses['A'], Masses['Ebinding'], alpha=0.7, lw=2,\n",
    "            label='Ame2016')\n",
    "ax.plot(Masses['A'], Masses['Eapprox'], alpha=0.7, lw=2, c='m',\n",
    "            label='Fit')\n",
    "ax.legend()\n",
    "save_fig(\"Masses2016\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a teaser, let us now see how we can do this with decision trees using **scikit-learn**. Later we will switch to so-called **random forests**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Decision Tree Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr_1=DecisionTreeRegressor(max_depth=5)\n",
    "regr_2=DecisionTreeRegressor(max_depth=7)\n",
    "regr_3=DecisionTreeRegressor(max_depth=9)\n",
    "regr_1.fit(X, Energies)\n",
    "regr_2.fit(X, Energies)\n",
    "regr_3.fit(X, Energies)\n",
    "\n",
    "\n",
    "y_1 = regr_1.predict(X)\n",
    "y_2 = regr_2.predict(X)\n",
    "y_3=regr_3.predict(X)\n",
    "Masses['Eapprox'] = y_3\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(A, Energies, color=\"blue\", label=\"Data\", linewidth=2)\n",
    "plt.plot(A, y_1, color=\"red\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.plot(A, y_2, color=\"green\", label=\"max_depth=7\", linewidth=2)\n",
    "plt.plot(A, y_3, color=\"m\", label=\"max_depth=9\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"$A$\")\n",
    "plt.ylabel(\"$E$[MeV]\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "save_fig(\"Masses2016Trees\")\n",
    "plt.show()\n",
    "print(Masses)\n",
    "print(np.mean( (Energies-y_1)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **seaborn** package allows us to visualize data in an efficient way. Note that we use **scikit-learn**'s multi-layer perceptron (or feed forward neural network) \n",
    "functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "X_train = X\n",
    "Y_train = Energies\n",
    "n_hidden_neurons = 100\n",
    "epochs = 100\n",
    "# store models for later use\n",
    "eta_vals = np.logspace(-5, 1, 7)\n",
    "lmbd_vals = np.logspace(-5, 1, 7)\n",
    "# store the models for later use\n",
    "DNN_scikit = np.zeros((len(eta_vals), len(lmbd_vals)), dtype=object)\n",
    "train_accuracy = np.zeros((len(eta_vals), len(lmbd_vals)))\n",
    "sns.set()\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmbd in enumerate(lmbd_vals):\n",
    "        dnn = MLPRegressor(hidden_layer_sizes=(n_hidden_neurons), activation='logistic',\n",
    "                            alpha=lmbd, learning_rate_init=eta, max_iter=epochs)\n",
    "        dnn.fit(X_train, Y_train)\n",
    "        DNN_scikit[i][j] = dnn\n",
    "        train_accuracy[i][j] = dnn.score(X_train, Y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "sns.heatmap(train_accuracy, annot=True, ax=ax, cmap=\"viridis\")\n",
    "ax.set_title(\"Training Accuracy\")\n",
    "ax.set_ylabel(\"$\\eta$\")\n",
    "ax.set_xlabel(\"$\\lambda$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression, basic elements\n",
    "\n",
    "\n",
    "[Video of Lecture](https://www.uio.no/studier/emner/matnat/fys/FYS-STK4155/h20/forelesningsvideoer/LectureAug27.mp4?vrtx=view-as-webpage).\n",
    "\n",
    "\n",
    "Fitting a continuous function with linear parameterization in terms of the parameters  $\\boldsymbol{\\beta}$.\n",
    "* Method of choice for fitting a continuous function!\n",
    "\n",
    "* Gives an excellent introduction to central Machine Learning features with **understandable pedagogical** links to other methods like **Neural Networks**, **Support Vector Machines** etc\n",
    "\n",
    "* Analytical expression for the fitting parameters $\\boldsymbol{\\beta}$\n",
    "\n",
    "* Analytical expressions for statistical propertiers like mean values, variances, confidence intervals and more\n",
    "\n",
    "* Analytical relation with probabilistic interpretations \n",
    "\n",
    "* Easy to introduce basic concepts like bias-variance tradeoff, cross-validation, resampling and regularization techniques and many other ML topics\n",
    "\n",
    "* Easy to code! And links well with classification problems and logistic regression and neural networks\n",
    "\n",
    "* Allows for **easy** hands-on understanding of gradient descent methods\n",
    "\n",
    "* and many more features\n",
    "\n",
    "For more discussions of Ridge and Lasso regression, [Wessel van Wieringen's](https://arxiv.org/abs/1509.09169) article is highly recommended.\n",
    "Similarly, [Mehta et al's article](https://arxiv.org/abs/1803.08823) is also recommended.\n",
    "\n",
    "\n",
    "\n",
    "Regression modeling deals with the description of  the sampling distribution of a given random variable $y$ and how it varies as function of another variable or a set of such variables $\\boldsymbol{x} =[x_0, x_1,\\dots, x_{n-1}]^T$. \n",
    "The first variable is called the **dependent**, the **outcome** or the **response** variable while the set of variables $\\boldsymbol{x}$ is called the independent variable, or the predictor variable or the explanatory variable. \n",
    "\n",
    "A regression model aims at finding a likelihood function $p(\\boldsymbol{y}\\vert \\boldsymbol{x})$, that is the conditional distribution for $\\boldsymbol{y}$ with a given $\\boldsymbol{x}$. The estimation of  $p(\\boldsymbol{y}\\vert \\boldsymbol{x})$ is made using a data set with \n",
    "* $n$ cases $i = 0, 1, 2, \\dots, n-1$ \n",
    "\n",
    "* Response (target, dependent or outcome) variable $y_i$ with $i = 0, 1, 2, \\dots, n-1$ \n",
    "\n",
    "* $p$ so-called explanatory (independent or predictor) variables $\\boldsymbol{x}_i=[x_{i0}, x_{i1}, \\dots, x_{ip-1}]$ with $i = 0, 1, 2, \\dots, n-1$ and explanatory variables running from $0$ to $p-1$. See below for more explicit examples.   \n",
    "\n",
    " The goal of the regression analysis is to extract/exploit relationship between $\\boldsymbol{y}$ and $\\boldsymbol{x}$ in or to infer causal dependencies, approximations to the likelihood functions, functional relationships and to make predictions, making fits and many other things.\n",
    "\n",
    "\n",
    "Consider an experiment in which $p$ characteristics of $n$ samples are\n",
    "measured. The data from this experiment, for various explanatory variables $p$ are normally represented by a matrix  \n",
    "$\\mathbf{X}$.\n",
    "\n",
    "The matrix $\\mathbf{X}$ is called the *design\n",
    "matrix*. Additional information of the samples is available in the\n",
    "form of $\\boldsymbol{y}$ (also as above). The variable $\\boldsymbol{y}$ is\n",
    "generally referred to as the *response variable*. The aim of\n",
    "regression analysis is to explain $\\boldsymbol{y}$ in terms of\n",
    "$\\boldsymbol{X}$ through a functional relationship like $y_i =\n",
    "f(\\mathbf{X}_{i,\\ast})$. When no prior knowledge on the form of\n",
    "$f(\\cdot)$ is available, it is common to assume a linear relationship\n",
    "between $\\boldsymbol{X}$ and $\\boldsymbol{y}$. This assumption gives rise to\n",
    "the *linear regression model* where $\\boldsymbol{\\beta} = [\\beta_0, \\ldots,\n",
    "\\beta_{p-1}]^{T}$ are the *regression parameters*. \n",
    "\n",
    "Linear regression gives us a set of analytical equations for the parameters $\\beta_j$.\n",
    "\n",
    "\n",
    "In order to understand the relation among the predictors $p$, the set of data $n$ and the target (outcome, output etc) $\\boldsymbol{y}$,\n",
    "consider the model we discussed for describing nuclear binding energies. \n",
    "\n",
    "There we assumed that we could parametrize the data using a polynomial approximation based on the liquid drop model.\n",
    "Assuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "BE(A) = a_0+a_1A+a_2A^{2/3}+a_3A^{-1/3}+a_4A^{-1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have five predictors, that is the intercept, the $A$ dependent term, the $A^{2/3}$ term and the $A^{-1/3}$ and $A^{-1}$ terms.\n",
    "This gives $p=0,1,2,3,4$. Furthermore we have $n$ entries for each predictor. It means that our design matrix is a \n",
    "$p\\times n$ matrix $\\boldsymbol{X}$.\n",
    "\n",
    "Here the predictors are based on a model we have made. A popular data set which is widely encountered in ML applications is the\n",
    "so-called [credit card default data from Taiwan](https://www.sciencedirect.com/science/article/pii/S0957417407006719?via%3Dihub). The data set contains data on $n=30000$ credit card holders with predictors like gender, marital status, age, profession, education, etc. In total there are $24$ such predictors or attributes leading to a design matrix of dimensionality $24 \\times 30000$. This is however a classification problem and we will come back to it when we discuss Logistic Regression. \n",
    "\n",
    "\n",
    "Before we proceed let us study a case from linear algebra where we aim at fitting a set of data $\\boldsymbol{y}=[y_0,y_1,\\dots,y_{n-1}]$. We could think of these data as a result of an experiment or a complicated numerical experiment. These data are functions of a series of variables $\\boldsymbol{x}=[x_0,x_1,\\dots,x_{n-1}]$, that is $y_i = y(x_i)$ with $i=0,1,2,\\dots,n-1$. The variables $x_i$ could represent physical quantities like time, temperature, position etc. We assume that $y(x)$ is a smooth function. \n",
    "\n",
    "Since obtaining these data points may not be trivial, we want to use these data to fit a function which can allow us to make predictions for values of $y$ which are not in the present set. The perhaps simplest approach is to assume we can parametrize our function in terms of a polynomial of degree $n-1$ with $n$ points, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y=y(x) \\rightarrow y(x_i)=\\tilde{y}_i+\\epsilon_i=\\sum_{j=0}^{n-1} \\beta_j x_i^j+\\epsilon_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon_i$ is the error in our approximation. \n",
    "\n",
    "\n",
    "For every set of values $y_i,x_i$ we have thus the corresponding set of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0+\\beta_1x_0^1+\\beta_2x_0^2+\\dots+\\beta_{n-1}x_0^{n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0+\\beta_1x_1^1+\\beta_2x_1^2+\\dots+\\beta_{n-1}x_1^{n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0+\\beta_1x_2^1+\\beta_2x_2^2+\\dots+\\beta_{n-1}x_2^{n-1}+\\epsilon_2\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0+\\beta_1x_{n-1}^1+\\beta_2x_{n-1}^2+\\dots+\\beta_{n-1}x_{n-1}^{n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{y} = [y_0,y_1, y_2,\\dots, y_{n-1}]^T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\beta} = [\\beta_0,\\beta_1, \\beta_2,\\dots, \\beta_{n-1}]^T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\epsilon} = [\\epsilon_0,\\epsilon_1, \\epsilon_2,\\dots, \\epsilon_{n-1}]^T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the design matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{X}=\n",
    "\\begin{bmatrix} \n",
    "1& x_{0}^1 &x_{0}^2& \\dots & \\dots &x_{0}^{n-1}\\\\\n",
    "1& x_{1}^1 &x_{1}^2& \\dots & \\dots &x_{1}^{n-1}\\\\\n",
    "1& x_{2}^1 &x_{2}^2& \\dots & \\dots &x_{2}^{n-1}\\\\                      \n",
    "\\dots& \\dots &\\dots& \\dots & \\dots &\\dots\\\\\n",
    "1& x_{n-1}^1 &x_{n-1}^2& \\dots & \\dots &x_{n-1}^{n-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can rewrite our equations as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above design matrix is called a [Vandermonde matrix](https://en.wikipedia.org/wiki/Vandermonde_matrix).\n",
    "\n",
    "We are obviously not limited to the above polynomial expansions.  We\n",
    "could replace the various powers of $x$ with elements of Fourier\n",
    "series or instead of $x_i^j$ we could have $\\cos{(j x_i)}$ or $\\sin{(j\n",
    "x_i)}$, or time series or other orthogonal functions.  For every set\n",
    "of values $y_i,x_i$ we can then generalize the equations to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0x_{00}+\\beta_1x_{01}+\\beta_2x_{02}+\\dots+\\beta_{n-1}x_{0n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0x_{10}+\\beta_1x_{11}+\\beta_2x_{12}+\\dots+\\beta_{n-1}x_{1n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0x_{20}+\\beta_1x_{21}+\\beta_2x_{22}+\\dots+\\beta_{n-1}x_{2n-1}+\\epsilon_2\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{i}&=\\beta_0x_{i0}+\\beta_1x_{i1}+\\beta_2x_{i2}+\\dots+\\beta_{n-1}x_{in-1}+\\epsilon_i\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0x_{n-1,0}+\\beta_1x_{n-1,2}+\\beta_2x_{n-1,2}+\\dots+\\beta_{n-1}x_{n-1,n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that we have $p=n$ here. The matrix is symmetric. This is generally not the case!**\n",
    "\n",
    "We redefine in turn the matrix $\\boldsymbol{X}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{X}=\n",
    "\\begin{bmatrix} \n",
    "x_{00}& x_{01} &x_{02}& \\dots & \\dots &x_{0,n-1}\\\\\n",
    "x_{10}& x_{11} &x_{12}& \\dots & \\dots &x_{1,n-1}\\\\\n",
    "x_{20}& x_{21} &x_{22}& \\dots & \\dots &x_{2,n-1}\\\\                      \n",
    "\\dots& \\dots &\\dots& \\dots & \\dots &\\dots\\\\\n",
    "x_{n-1,0}& x_{n-1,1} &x_{n-1,2}& \\dots & \\dots &x_{n-1,n-1}\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and without loss of generality we rewrite again  our equations as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{y} = \\boldsymbol{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side of this equation is kwown. Our error vector $\\boldsymbol{\\epsilon}$ and the parameter vector $\\boldsymbol{\\beta}$ are our unknow quantities. How can we obtain the optimal set of $\\beta_i$ values? \n",
    "\n",
    "We have defined the matrix $\\boldsymbol{X}$ via the equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "y_0&=\\beta_0x_{00}+\\beta_1x_{01}+\\beta_2x_{02}+\\dots+\\beta_{n-1}x_{0n-1}+\\epsilon_0\\\\\n",
    "y_1&=\\beta_0x_{10}+\\beta_1x_{11}+\\beta_2x_{12}+\\dots+\\beta_{n-1}x_{1n-1}+\\epsilon_1\\\\\n",
    "y_2&=\\beta_0x_{20}+\\beta_1x_{21}+\\beta_2x_{22}+\\dots+\\beta_{n-1}x_{2n-1}+\\epsilon_1\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{i}&=\\beta_0x_{i0}+\\beta_1x_{i1}+\\beta_2x_{i2}+\\dots+\\beta_{n-1}x_{in-1}+\\epsilon_1\\\\\n",
    "\\dots & \\dots \\\\\n",
    "y_{n-1}&=\\beta_0x_{n-1,0}+\\beta_1x_{n-1,2}+\\beta_2x_{n-1,2}+\\dots+\\beta_{n-1}x_{n-1,n-1}+\\epsilon_{n-1}.\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noted above, we stayed with a system with the design matrix \n",
    " $\\boldsymbol{X}\\in {\\mathbb{R}}^{n\\times n}$, that is we have $p=n$. For reasons to come later (algorithmic arguments) we will hereafter define \n",
    "our matrix as $\\boldsymbol{X}\\in {\\mathbb{R}}^{n\\times p}$, with the predictors refering to the column numbers and the entries $n$ being the row elements.\n",
    "\n",
    "In our [introductory notes](https://compphysics.github.io/MachineLearning/doc/pub/How2ReadData/html/How2ReadData.html) we looked at the so-called [liquid drop model](https://en.wikipedia.org/wiki/Semi-empirical_mass_formula). Let us remind ourselves about what we did by looking at the code.\n",
    "\n",
    "We restate the parts of the code we are most interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "infile = open(data_path(\"MassEval2016.dat\"),'r')\n",
    "\n",
    "\n",
    "# Read the experimental data with Pandas\n",
    "Masses = pd.read_fwf(infile, usecols=(2,3,4,6,11),\n",
    "              names=('N', 'Z', 'A', 'Element', 'Ebinding'),\n",
    "              widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),\n",
    "              header=39,\n",
    "              index_col=False)\n",
    "\n",
    "# Extrapolated values are indicated by '#' in place of the decimal place, so\n",
    "# the Ebinding column won't be numeric. Coerce to float and drop these entries.\n",
    "Masses['Ebinding'] = pd.to_numeric(Masses['Ebinding'], errors='coerce')\n",
    "Masses = Masses.dropna()\n",
    "# Convert from keV to MeV.\n",
    "Masses['Ebinding'] /= 1000\n",
    "\n",
    "# Group the DataFrame by nucleon number, A.\n",
    "Masses = Masses.groupby('A')\n",
    "# Find the rows of the grouped DataFrame with the maximum binding energy.\n",
    "Masses = Masses.apply(lambda t: t[t.Ebinding==t.Ebinding.max()])\n",
    "A = Masses['A']\n",
    "Z = Masses['Z']\n",
    "N = Masses['N']\n",
    "Element = Masses['Element']\n",
    "Energies = Masses['Ebinding']\n",
    "\n",
    "# Now we set up the design matrix X\n",
    "X = np.zeros((len(A),5))\n",
    "X[:,0] = 1\n",
    "X[:,1] = A\n",
    "X[:,2] = A**(2.0/3.0)\n",
    "X[:,3] = A**(-1.0/3.0)\n",
    "X[:,4] = A**(-1.0)\n",
    "# Then nice printout using pandas\n",
    "DesignMatrix = pd.DataFrame(X)\n",
    "DesignMatrix.index = A\n",
    "DesignMatrix.columns = ['1', 'A', 'A^(2/3)', 'A^(-1/3)', '1/A']\n",
    "display(DesignMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $\\boldsymbol{\\beta}\\in {\\mathbb{R}}^{p\\times 1}$, it means that we will hereafter write our equations for the approximation as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\tilde{y}}= \\boldsymbol{X}\\boldsymbol{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "throughout these lectures. \n",
    "\n",
    "With the above we use the design matrix to define the approximation $\\boldsymbol{\\tilde{y}}$ via the unknown quantity $\\boldsymbol{\\beta}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\tilde{y}}= \\boldsymbol{X}\\boldsymbol{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and in order to find the optimal parameters $\\beta_i$ instead of solving the above linear algebra problem, we define a function which gives a measure of the spread between the values $y_i$ (which represent hopefully the exact values) and the parameterized values $\\tilde{y}_i$, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C(\\boldsymbol{\\beta})=\\frac{1}{n}\\sum_{i=0}^{n-1}\\left(y_i-\\tilde{y}_i\\right)^2=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{\\tilde{y}}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{\\tilde{y}}\\right)\\right\\},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using the matrix $\\boldsymbol{X}$ and in a more compact matrix-vector notation as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C(\\boldsymbol{\\beta})=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is one possible way to define the so-called cost function.\n",
    "\n",
    "\n",
    "\n",
    "It is also common to define\n",
    "the function $C$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C(\\boldsymbol{\\beta})=\\frac{1}{2n}\\sum_{i=0}^{n-1}\\left(y_i-\\tilde{y}_i\\right)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since when taking the first derivative with respect to the unknown parameters $\\beta$, the factor of $2$ cancels out. \n",
    "\n",
    "The function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C(\\boldsymbol{\\beta})=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)\\right\\},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be linked to the variance of the quantity $y_i$ if we interpret the latter as the mean value. \n",
    "When linking (see the discussion below) with the maximum likelihood approach below, we will indeed interpret $y_i$ as a mean value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_{i}=\\langle y_i \\rangle = \\beta_0x_{i,0}+\\beta_1x_{i,1}+\\beta_2x_{i,2}+\\dots+\\beta_{n-1}x_{i,n-1}+\\epsilon_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\langle y_i \\rangle$ is the mean value. Keep in mind also that\n",
    "till now we have treated $y_i$ as the exact value. Normally, the\n",
    "response (dependent or outcome) variable $y_i$ the outcome of a\n",
    "numerical experiment or another type of experiment and is thus only an\n",
    "approximation to the true value. It is then always accompanied by an\n",
    "error estimate, often limited to a statistical error estimate given by\n",
    "the standard deviation discussed earlier. In the discussion here we\n",
    "will treat $y_i$ as our exact value for the response variable.\n",
    "\n",
    "In order to find the parameters $\\beta_i$ we will then minimize the spread of $C(\\boldsymbol{\\beta})$, that is we are going to solve the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\displaystyle \\min_{\\boldsymbol{\\beta}\\in\n",
    "{\\mathbb{R}}^{p}}}\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practical terms it means we will require"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C(\\boldsymbol{\\beta})}{\\partial \\beta_j} = \\frac{\\partial }{\\partial \\beta_j}\\left[ \\frac{1}{n}\\sum_{i=0}^{n-1}\\left(y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}\\right)^2\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C(\\boldsymbol{\\beta})}{\\partial \\beta_j} = -\\frac{2}{n}\\left[ \\sum_{i=0}^{n-1}x_{ij}\\left(y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or in a matrix-vector form as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = 0 = \\boldsymbol{X}^T\\left( \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial C(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = 0 = \\boldsymbol{X}^T\\left( \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{X}^T\\boldsymbol{y} = \\boldsymbol{X}^T\\boldsymbol{X}\\boldsymbol{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the matrix $\\boldsymbol{X}^T\\boldsymbol{X}$ is invertible we have the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\beta} =\\left(\\boldsymbol{X}^T\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note also that since our design matrix is defined as $\\boldsymbol{X}\\in\n",
    "{\\mathbb{R}}^{n\\times p}$, the product $\\boldsymbol{X}^T\\boldsymbol{X} \\in\n",
    "{\\mathbb{R}}^{p\\times p}$.  In the above case we have that $p \\ll n$,\n",
    "in our case $p=5$ meaning that we end up with inverting a small\n",
    "$5\\times 5$ matrix. This is a rather common situation, in many cases we end up with low-dimensional\n",
    "matrices to invert. The methods discussed here and for many other\n",
    "supervised learning algorithms like classification with logistic\n",
    "regression or support vector machines, exhibit dimensionalities which\n",
    "allow for the usage of direct linear algebra methods such as **LU** decomposition or **Singular Value Decomposition** (SVD) for finding the inverse of the matrix\n",
    "$\\boldsymbol{X}^T\\boldsymbol{X}$. \n",
    "\n",
    "**Small question**: Do you think the example we have at hand here (the nuclear binding energies) can lead to problems in inverting the matrix  $\\boldsymbol{X}^T\\boldsymbol{X}$? What kind of problems can we expect? \n",
    "\n",
    "\n",
    "The following matrix and vector relation will be useful here and for the rest of the course. Vectors are always written as boldfaced lower case letters and \n",
    "matrices as upper case boldfaced letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "3\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "4\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\n",
    "5\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial\\log{\\vert\\boldsymbol{A}\\vert}}{\\partial \\boldsymbol{A}}=(\\boldsymbol{A}^{-1})^T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals $\\boldsymbol{\\epsilon}$ are in turn given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\epsilon} = \\boldsymbol{y}-\\boldsymbol{\\tilde{y}} = \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{X}^T\\left( \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)= 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{X}^T\\boldsymbol{\\epsilon}=\\boldsymbol{X}^T\\left( \\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right)= 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meaning that the solution for $\\boldsymbol{\\beta}$ is the one which minimizes the residuals.  Later we will link this with the maximum likelihood approach.\n",
    "\n",
    "\n",
    "Let us now return to our nuclear binding energies and simply code the above equations. \n",
    "\n",
    "\n",
    "It is rather straightforward to implement the matrix inversion and obtain the parameters $\\boldsymbol{\\beta}$. After having defined the matrix $\\boldsymbol{X}$ we simply need to \n",
    "write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix inversion to find beta\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Energies)\n",
    "# and then make the prediction\n",
    "ytilde = X @ beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the least squares functionality in **Numpy** as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.linalg.lstsq(X, Energies, rcond =None)[0]\n",
    "ytildenp = np.dot(fit,X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we plot our fit with and compare with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Masses['Eapprox']  = ytilde\n",
    "# Generate a plot comparing the experimental with the fitted values values.\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$A = N + Z$')\n",
    "ax.set_ylabel(r'$E_\\mathrm{bind}\\,/\\mathrm{MeV}$')\n",
    "ax.plot(Masses['A'], Masses['Ebinding'], alpha=0.7, lw=2,\n",
    "            label='Ame2016')\n",
    "ax.plot(Masses['A'], Masses['Eapprox'], alpha=0.7, lw=2, c='m',\n",
    "            label='Fit')\n",
    "ax.legend()\n",
    "save_fig(\"Masses2016OLS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily test our fit by computing the $R2$ score that we discussed in connection with the functionality of **Scikit-Learn** in the introductory slides.\n",
    "Since we are not using **Scikit-Learn** here we can define our own $R2$ function as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we would be using it as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R2(Energies,ytilde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily add our **MSE** score as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "print(MSE(Energies,ytilde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally the relative error as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RelativeError(y_data,y_model):\n",
    "    return abs((y_data-y_model)/y_data)\n",
    "print(RelativeError(Energies, ytilde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The $\\chi^2$ function\n",
    "\n",
    "Normally, the response (dependent or outcome) variable $y_i$ is the\n",
    "outcome of a numerical experiment or another type of experiment and is\n",
    "thus only an approximation to the true value. It is then always\n",
    "accompanied by an error estimate, often limited to a statistical error\n",
    "estimate given by the standard deviation discussed earlier. In the\n",
    "discussion here we will treat $y_i$ as our exact value for the\n",
    "response variable.\n",
    "\n",
    "Introducing the standard deviation $\\sigma_i$ for each measurement\n",
    "$y_i$, we define now the $\\chi^2$ function (omitting the $1/n$ term)\n",
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2(\\boldsymbol{\\beta})=\\frac{1}{n}\\sum_{i=0}^{n-1}\\frac{\\left(y_i-\\tilde{y}_i\\right)^2}{\\sigma_i^2}=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{\\tilde{y}}\\right)^T\\frac{1}{\\boldsymbol{\\Sigma^2}}\\left(\\boldsymbol{y}-\\boldsymbol{\\tilde{y}}\\right)\\right\\},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the matrix $\\boldsymbol{\\Sigma}$ is a diagonal matrix with $\\sigma_i$ as matrix elements. \n",
    "\n",
    "\n",
    "In order to find the parameters $\\beta_i$ we will then minimize the spread of $\\chi^2(\\boldsymbol{\\beta})$ by requiring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\beta_j} = \\frac{\\partial }{\\partial \\beta_j}\\left[ \\frac{1}{n}\\sum_{i=0}^{n-1}\\left(\\frac{y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}}{\\sigma_i}\\right)^2\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\beta_j} = -\\frac{2}{n}\\left[ \\sum_{i=0}^{n-1}\\frac{x_{ij}}{\\sigma_i}\\left(\\frac{y_i-\\beta_0x_{i,0}-\\beta_1x_{i,1}-\\beta_2x_{i,2}-\\dots-\\beta_{n-1}x_{i,n-1}}{\\sigma_i}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or in a matrix-vector form as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = 0 = \\boldsymbol{A}^T\\left( \\boldsymbol{b}-\\boldsymbol{A}\\boldsymbol{\\beta}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have defined the matrix $\\boldsymbol{A} =\\boldsymbol{X}/\\boldsymbol{\\Sigma}$ with matrix elements $a_{ij} = x_{ij}/\\sigma_i$ and the vector $\\boldsymbol{b}$ with elements $b_i = y_i/\\sigma_i$.   \n",
    "\n",
    "We can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = 0 = \\boldsymbol{A}^T\\left( \\boldsymbol{b}-\\boldsymbol{A}\\boldsymbol{\\beta}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{A}^T\\boldsymbol{b} = \\boldsymbol{A}^T\\boldsymbol{A}\\boldsymbol{\\beta},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the matrix $\\boldsymbol{A}^T\\boldsymbol{A}$ is invertible we have the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\beta} =\\left(\\boldsymbol{A}^T\\boldsymbol{A}\\right)^{-1}\\boldsymbol{A}^T\\boldsymbol{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we then introduce the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{H} =  \\left(\\boldsymbol{A}^T\\boldsymbol{A}\\right)^{-1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have then the following expression for the parameters $\\beta_j$ (the matrix elements of $\\boldsymbol{H}$ are $h_{ij}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_j = \\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}\\frac{y_i}{\\sigma_i}\\frac{x_{ik}}{\\sigma_i} = \\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}b_ia_{ik}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We state without proof the expression for the uncertainty  in the parameters $\\beta_j$ as (we leave this as an exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\beta_j) = \\sum_{i=0}^{n-1}\\sigma_i^2\\left( \\frac{\\partial \\beta_j}{\\partial y_i}\\right)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma^2(\\beta_j) = \\left(\\sum_{k=0}^{p-1}h_{jk}\\sum_{i=0}^{n-1}a_{ik}\\right)\\left(\\sum_{l=0}^{p-1}h_{jl}\\sum_{m=0}^{n-1}a_{ml}\\right) = h_{jj}!\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step here is to approximate the function $y$ with a first-order polynomial, that is we write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y=y(x) \\rightarrow y(x_i) \\approx \\beta_0+\\beta_1 x_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By computing the derivatives of $\\chi^2$ with respect to $\\beta_0$ and $\\beta_1$ show that these are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\beta_0} = -2\\left[ \\frac{1}{n}\\sum_{i=0}^{n-1}\\left(\\frac{y_i-\\beta_0-\\beta_1x_{i}}{\\sigma_i^2}\\right)\\right]=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\chi^2(\\boldsymbol{\\beta})}{\\partial \\beta_1} = -\\frac{2}{n}\\left[ \\sum_{i=0}^{n-1}x_i\\left(\\frac{y_i-\\beta_0-\\beta_1x_{i}}{\\sigma_i^2}\\right)\\right]=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear fit (a first-order polynomial) we don't need to invert a matrix!!  \n",
    "Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma =  \\sum_{i=0}^{n-1}\\frac{1}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_x =  \\sum_{i=0}^{n-1}\\frac{x_{i}}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_y = \\sum_{i=0}^{n-1}\\left(\\frac{y_i}{\\sigma_i^2}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_{xx} =  \\sum_{i=0}^{n-1}\\frac{x_ix_{i}}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\gamma_{xy} = \\sum_{i=0}^{n-1}\\frac{y_ix_{i}}{\\sigma_i^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_0 = \\frac{\\gamma_{xx}\\gamma_y-\\gamma_x\\gamma_y}{\\gamma\\gamma_{xx}-\\gamma_x^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta_1 = \\frac{\\gamma_{xy}\\gamma-\\gamma_x\\gamma_y}{\\gamma\\gamma_{xx}-\\gamma_x^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach (different linear and non-linear regression) suffers\n",
    "often from both being underdetermined and overdetermined in the\n",
    "unknown coefficients $\\beta_i$.  A better approach is to use the\n",
    "Singular Value Decomposition (SVD) method discussed below. Or using\n",
    "Lasso and Ridge regression. See below.\n",
    "\n",
    "\n",
    "### Fitting an Equation of State for Dense Nuclear Matter\n",
    "\n",
    "Before we continue, let us introduce yet another example. We are going to fit the\n",
    "nuclear equation of state using results from many-body calculations.\n",
    "The equation of state we have made available here, as function of\n",
    "density, has been derived using modern nucleon-nucleon potentials with\n",
    "[the addition of three-body\n",
    "forces](https://www.sciencedirect.com/science/article/pii/S0370157399001106). This\n",
    "time the file is presented as a standard **csv** file.\n",
    "\n",
    "The beginning of the Python code here is similar to what you have seen\n",
    "before, with the same initializations and declarations. We use also\n",
    "**pandas** again, rather extensively in order to organize our data.\n",
    "\n",
    "The difference now is that we use **Scikit-Learn's** regression tools\n",
    "instead of our own matrix inversion implementation. Furthermore, we\n",
    "sneak in **Ridge** regression (to be discussed below) which includes a\n",
    "hyperparameter $\\lambda$, also to be explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "infile = open(data_path(\"EoS.csv\"),'r')\n",
    "\n",
    "# Read the EoS data as  csv file and organize the data into two arrays with density and energies\n",
    "EoS = pd.read_csv(infile, names=('Density', 'Energy'))\n",
    "EoS['Energy'] = pd.to_numeric(EoS['Energy'], errors='coerce')\n",
    "EoS = EoS.dropna()\n",
    "Energies = EoS['Energy']\n",
    "Density = EoS['Density']\n",
    "#  The design matrix now as function of various polytrops\n",
    "X = np.zeros((len(Density),4))\n",
    "X[:,3] = Density**(4.0/3.0)\n",
    "X[:,2] = Density\n",
    "X[:,1] = Density**(2.0/3.0)\n",
    "X[:,0] = 1\n",
    "\n",
    "# We use now Scikit-Learn's linear regressor and ridge regressor\n",
    "# OLS part\n",
    "clf = skl.LinearRegression().fit(X, Energies)\n",
    "ytilde = clf.predict(X)\n",
    "EoS['Eols']  = ytilde\n",
    "# The mean squared error                               \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Energies, ytilde))\n",
    "# Explained variance score: 1 is perfect prediction                                 \n",
    "print('Variance score: %.2f' % r2_score(Energies, ytilde))\n",
    "# Mean absolute error                                                           \n",
    "print('Mean absolute error: %.2f' % mean_absolute_error(Energies, ytilde))\n",
    "print(clf.coef_, clf.intercept_)\n",
    "\n",
    "# The Ridge regression with a hyperparameter lambda = 0.1\n",
    "_lambda = 0.1\n",
    "clf_ridge = skl.Ridge(alpha=_lambda).fit(X, Energies)\n",
    "yridge = clf_ridge.predict(X)\n",
    "EoS['Eridge']  = yridge\n",
    "# The mean squared error                               \n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Energies, yridge))\n",
    "# Explained variance score: 1 is perfect prediction                                 \n",
    "print('Variance score: %.2f' % r2_score(Energies, yridge))\n",
    "# Mean absolute error                                                           \n",
    "print('Mean absolute error: %.2f' % mean_absolute_error(Energies, yridge))\n",
    "print(clf_ridge.coef_, clf_ridge.intercept_)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'$\\rho[\\mathrm{fm}^{-3}]$')\n",
    "ax.set_ylabel(r'Energy per particle')\n",
    "ax.plot(EoS['Density'], EoS['Energy'], alpha=0.7, lw=2,\n",
    "            label='Theoretical data')\n",
    "ax.plot(EoS['Density'], EoS['Eols'], alpha=0.7, lw=2, c='m',\n",
    "            label='OLS')\n",
    "ax.plot(EoS['Density'], EoS['Eridge'], alpha=0.7, lw=2, c='g',\n",
    "            label='Ridge $\\lambda = 0.1$')\n",
    "ax.legend()\n",
    "save_fig(\"EoSfitting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above simple polynomial in density $\\rho$ gives an excellent fit\n",
    "to the data. \n",
    "\n",
    "We note also that there is a small deviation between the\n",
    "standard OLS and the Ridge regression at higher densities. We discuss this in more detail\n",
    "below.\n",
    "\n",
    "\n",
    "## Splitting our Data in Training and Test data\n",
    "\n",
    "It is normal in essentially all Machine Learning studies to split the\n",
    "data in a training set and a test set (sometimes also an additional\n",
    "validation set).  **Scikit-Learn** has an own function for this. There\n",
    "is no explicit recipe for how much data should be included as training\n",
    "data and say test data.  An accepted rule of thumb is to use\n",
    "approximately $2/3$ to $4/5$ of the data as training data. We will\n",
    "postpone a discussion of this splitting to the end of these notes and\n",
    "our discussion of the so-called **bias-variance** tradeoff. Here we\n",
    "limit ourselves to repeat the above equation of state fitting example\n",
    "but now splitting the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "def R2(y_data, y_model):\n",
    "    return 1 - np.sum((y_data - y_model) ** 2) / np.sum((y_data - np.mean(y_data)) ** 2)\n",
    "def MSE(y_data,y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "infile = open(data_path(\"EoS.csv\"),'r')\n",
    "\n",
    "# Read the EoS data as  csv file and organized into two arrays with density and energies\n",
    "EoS = pd.read_csv(infile, names=('Density', 'Energy'))\n",
    "EoS['Energy'] = pd.to_numeric(EoS['Energy'], errors='coerce')\n",
    "EoS = EoS.dropna()\n",
    "Energies = EoS['Energy']\n",
    "Density = EoS['Density']\n",
    "#  The design matrix now as function of various polytrops\n",
    "X = np.zeros((len(Density),5))\n",
    "X[:,0] = 1\n",
    "X[:,1] = Density**(2.0/3.0)\n",
    "X[:,2] = Density\n",
    "X[:,3] = Density**(4.0/3.0)\n",
    "X[:,4] = Density**(5.0/3.0)\n",
    "# We split the data in test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Energies, test_size=0.2)\n",
    "# matrix inversion to find beta\n",
    "beta = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "# and then make the prediction\n",
    "ytilde = X_train @ beta\n",
    "print(\"Training R2\")\n",
    "print(R2(y_train,ytilde))\n",
    "print(\"Training MSE\")\n",
    "print(MSE(y_train,ytilde))\n",
    "ypredict = X_test @ beta\n",
    "print(\"Test R2\")\n",
    "print(R2(y_test,ypredict))\n",
    "print(\"Test MSE\")\n",
    "print(MSE(y_test,ypredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston housing data example\n",
    "\n",
    "The Boston housing  \n",
    "data set was originally a part of UCI Machine Learning Repository\n",
    "and has been removed now. The data set is now included in **Scikit-Learn**'s \n",
    "library.  There are 506 samples and 13 feature (predictor) variables\n",
    "in this data set. The objective is to predict the value of prices of\n",
    "the house using the features (predictors) listed here.\n",
    "\n",
    "The features/predictors are\n",
    "1. CRIM: Per capita crime rate by town\n",
    "\n",
    "2. ZN: Proportion of residential land zoned for lots over 25000 square feet\n",
    "\n",
    "3. INDUS: Proportion of non-retail business acres per town\n",
    "\n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "5. NOX: Nitric oxide concentration (parts per 10 million)\n",
    "\n",
    "6. RM: Average number of rooms per dwelling\n",
    "\n",
    "7. AGE: Proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "8. DIS: Weighted distances to five Boston employment centers\n",
    "\n",
    "9. RAD: Index of accessibility to radial highways\n",
    "\n",
    "10. TAX: Full-value property tax rate per USD10000\n",
    "\n",
    "11. B: $1000(Bk - 0.63)^2$, where $Bk$ is the proportion of [people of African American descent] by town\n",
    "\n",
    "12. LSTAT: Percentage of lower status of the population\n",
    "\n",
    "13. MEDV: Median value of owner-occupied homes in USD 1000s\n",
    "\n",
    "## Housing data, the code\n",
    "We start by importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and load the Boston Housing DataSet from **Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "# boston_dataset is a dictionary\n",
    "# let's check what it contains\n",
    "boston_dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we invoke Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()\n",
    "boston['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in all the columns\n",
    "boston.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of the figure\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "\n",
    "# plot a histogram showing the distribution of the target values\n",
    "sns.distplot(boston['MEDV'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now useful to look at the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the pair wise correlation for all columns  \n",
    "correlation_matrix = boston.corr().round(2)\n",
    "# use the heatmap function from seaborn to plot the correlation matrix\n",
    "# annot = True to print the values inside the square\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above coorelation plot we can see that **MEDV** is strongly correlated to **LSTAT** and  **RM**. We see also that **RAD** and **TAX** are stronly correlated, but we don't include this in our features together to avoid multi-colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "features = ['LSTAT', 'RM']\n",
    "target = boston['MEDV']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features) , i+1)\n",
    "    x = boston[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker='o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.c_[boston['LSTAT'], boston['RM']], columns = ['LSTAT','RM'])\n",
    "Y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splits the training and test data set in 80% : 20%\n",
    "# assign random_state to any value.This ensures consistency.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the linear regression functionality from **Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "\n",
    "# model evaluation for training set\n",
    "\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "y_test_predict = lin_model.predict(X_test)\n",
    "# root mean square error of the model\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "\n",
    "# r-squared score of the model\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the y_test vs y_pred\n",
    "# ideally should have been a straight line\n",
    "plt.scatter(Y_test, y_test_predict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing the number of degrees of freedom, overarching view\n",
    "\n",
    "Many Machine Learning problems involve thousands or even millions of\n",
    "features for each training instance. Not only does this make training\n",
    "extremely slow, it can also make it much harder to find a good\n",
    "solution, as we will see. This problem is often referred to as the\n",
    "curse of dimensionality.  Fortunately, in real-world problems, it is\n",
    "often possible to reduce the number of features considerably, turning\n",
    "an intractable problem into a tractable one.\n",
    "\n",
    "Later  we will discuss some of the most popular dimensionality reduction\n",
    "techniques: the principal component analysis (PCA), Kernel PCA, and\n",
    "Locally Linear Embedding (LLE).  \n",
    "\n",
    "\n",
    "Principal component analysis and its various variants deal with the\n",
    "problem of fitting a low-dimensional [affine\n",
    "subspace](https://en.wikipedia.org/wiki/Affine_space) to a set of of\n",
    "data points in a high-dimensional space. With its family of methods it\n",
    "is one of the most used tools in data modeling, compression and\n",
    "visualization.\n",
    "\n",
    "\n",
    "Before we proceed however, we will discuss how to preprocess our\n",
    "data. Till now and in connection with our previous examples we have\n",
    "not met so many cases where we are too sensitive to the scaling of our\n",
    "data. Normally the data may need a rescaling and/or may be sensitive\n",
    "to extreme values. Scaling the data renders our inputs much more\n",
    "suitable for the algorithms we want to employ.\n",
    "\n",
    "**Scikit-Learn** has several functions which allow us to rescale the\n",
    "data, normally resulting in much better results in terms of various\n",
    "accuracy scores.  The **StandardScaler** function in **Scikit-Learn**\n",
    "ensures that for each feature/predictor we study the mean value is\n",
    "zero and the variance is one (every column in the design/feature\n",
    "matrix).  This scaling has the drawback that it does not ensure that\n",
    "we have a particular maximum or minimum in our data set. Another\n",
    "function included in **Scikit-Learn** is the **MinMaxScaler** which\n",
    "ensures that all features are exactly between $0$ and $1$. The\n",
    "\n",
    "\n",
    "The **Normalizer** scales each data\n",
    "point such that the feature vector has a euclidean length of one. In other words, it\n",
    "projects a data point on the circle (or sphere in the case of higher dimensions) with a\n",
    "radius of 1. This means every data point is scaled by a different number (by the\n",
    "inverse of its length).\n",
    "This normalization is often used when only the direction (or angle) of the data matters,\n",
    "not the length of the feature vector.\n",
    "\n",
    "The **RobustScaler** works similarly to the StandardScaler in that it\n",
    "ensures statistical properties for each feature that guarantee that\n",
    "they are on the same scale. However, the RobustScaler uses the median\n",
    "and quartiles, instead of mean and variance. This makes the\n",
    "RobustScaler ignore data points that are very different from the rest\n",
    "(like measurement errors). These odd data points are also called\n",
    "outliers, and might often lead to trouble for other scaling\n",
    "techniques.\n",
    "\n",
    "\n",
    "### Simple preprocessing examples, Franke function and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "# Where to save the figures and data files\n",
    "PROJECT_ROOT_DIR = \"Results\"\n",
    "FIGURE_ID = \"Results/FigureFiles\"\n",
    "DATA_ID = \"DataFiles/\"\n",
    "\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    os.mkdir(PROJECT_ROOT_DIR)\n",
    "\n",
    "if not os.path.exists(FIGURE_ID):\n",
    "    os.makedirs(FIGURE_ID)\n",
    "\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(FIGURE_ID, fig_id)\n",
    "\n",
    "def data_path(dat_id):\n",
    "    return os.path.join(DATA_ID, dat_id)\n",
    "\n",
    "def save_fig(fig_id):\n",
    "    plt.savefig(image_path(fig_id) + \".png\", format='png')\n",
    "\n",
    "\n",
    "def FrankeFunction(x,y):\n",
    "\tterm1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n",
    "\tterm2 = 0.75*np.exp(-((9*x+1)**2)/49.0 - 0.1*(9*y+1))\n",
    "\tterm3 = 0.5*np.exp(-(9*x-7)**2/4.0 - 0.25*((9*y-3)**2))\n",
    "\tterm4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n",
    "\treturn term1 + term2 + term3 + term4\n",
    "\n",
    "\n",
    "def create_X(x, y, n ):\n",
    "\tif len(x.shape) > 1:\n",
    "\t\tx = np.ravel(x)\n",
    "\t\ty = np.ravel(y)\n",
    "\n",
    "\tN = len(x)\n",
    "\tl = int((n+1)*(n+2)/2)\t\t# Number of elements in beta\n",
    "\tX = np.ones((N,l))\n",
    "\n",
    "\tfor i in range(1,n+1):\n",
    "\t\tq = int((i)*(i+1)/2)\n",
    "\t\tfor k in range(i+1):\n",
    "\t\t\tX[:,q+k] = (x**(i-k))*(y**k)\n",
    "\n",
    "\treturn X\n",
    "\n",
    "\n",
    "# Making meshgrid of datapoints and compute Franke's function\n",
    "n = 5\n",
    "N = 1000\n",
    "x = np.sort(np.random.uniform(0, 1, N))\n",
    "y = np.sort(np.random.uniform(0, 1, N))\n",
    "z = FrankeFunction(x, y)\n",
    "X = create_X(x, y, n=n)    \n",
    "# split in training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,z,test_size=0.2)\n",
    "\n",
    "\n",
    "clf = skl.LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# The mean squared error and R2 score\n",
    "print(\"MSE before scaling: {:.2f}\".format(mean_squared_error(clf.predict(X_test), y_test)))\n",
    "print(\"R2 score before scaling {:.2f}\".format(clf.score(X_test,y_test)))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature min values before scaling:\\n {}\".format(X_train.min(axis=0)))\n",
    "print(\"Feature max values before scaling:\\n {}\".format(X_train.max(axis=0)))\n",
    "\n",
    "print(\"Feature min values after scaling:\\n {}\".format(X_train_scaled.min(axis=0)))\n",
    "print(\"Feature max values after scaling:\\n {}\".format(X_train_scaled.max(axis=0)))\n",
    "\n",
    "clf = skl.LinearRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(\"MSE after  scaling: {:.2f}\".format(mean_squared_error(clf.predict(X_test_scaled), y_test)))\n",
    "print(\"R2 score for  scaled data: {:.2f}\".format(clf.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise: Setting up various Python environments\n",
    "\n",
    "The first exercise here is of a mere technical art. We want you to have \n",
    "* git as a version control software and to establish a user account on a provider like GitHub. Other providers like GitLab etc are equally fine. You can also use the University of Oslo [GitHub facilities](https://www.uio.no/tjenester/it/maskin/filer/versjonskontroll/github.html). \n",
    "\n",
    "* Install various Python packages\n",
    "\n",
    "We will make extensive use of Python as programming language and its\n",
    "myriad of available libraries.  You will find\n",
    "IPython/Jupyter notebooks invaluable in your work.  You can run **R**\n",
    "codes in the Jupyter/IPython notebooks, with the immediate benefit of\n",
    "visualizing your data. You can also use compiled languages like C++,\n",
    "Rust, Fortran etc if you prefer. The focus in these lectures will be\n",
    "on Python.\n",
    "\n",
    "If you have Python installed (we recommend Python3) and you feel\n",
    "pretty familiar with installing different packages, we recommend that\n",
    "you install the following Python packages via **pip** as \n",
    "\n",
    "1. pip install numpy scipy matplotlib ipython scikit-learn sympy pandas pillow \n",
    "\n",
    "For **Tensorflow**, we recommend following the instructions in the text of \n",
    "[Aurelien Geron, HandsOn Machine Learning with ScikitLearn and TensorFlow, O'Reilly](http://shop.oreilly.com/product/0636920052289.do)\n",
    "\n",
    "We will come back to **tensorflow** later. \n",
    "\n",
    "For Python3, replace **pip** with **pip3**.\n",
    "\n",
    "For OSX users we recommend, after having installed Xcode, to\n",
    "install **brew**. Brew allows for a seamless installation of additional\n",
    "software via for example \n",
    "\n",
    "1. brew install python3\n",
    "\n",
    "For Linux users, with its variety of distributions like for example the widely popular Ubuntu distribution,\n",
    "you can use **pip** as well and simply install Python as \n",
    "\n",
    "1. sudo apt-get install python3  (or python for Python2.7)\n",
    "\n",
    "If you don't want to perform these operations separately and venture\n",
    "into the hassle of exploring how to set up dependencies and paths, we\n",
    "recommend two widely used distrubutions which set up all relevant\n",
    "dependencies for Python, namely \n",
    "\n",
    "* [Anaconda](https://docs.anaconda.com/), \n",
    "\n",
    "which is an open source\n",
    "distribution of the Python and R programming languages for large-scale\n",
    "data processing, predictive analytics, and scientific computing, that\n",
    "aims to simplify package management and deployment. Package versions\n",
    "are managed by the package management system **conda**. \n",
    "\n",
    "* [Enthought canopy](https://www.enthought.com/product/canopy/) \n",
    "\n",
    "is a Python\n",
    "distribution for scientific and analytic computing distribution and\n",
    "analysis environment, available for free and under a commercial\n",
    "license.\n",
    "\n",
    "We recommend using **Anaconda** if you are not too familiar with setting paths in a terminal environment.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exercise: making your own data and exploring scikit-learn\n",
    "\n",
    "We will generate our own dataset for a function $y(x)$ where $x \\in [0,1]$ and defined by random numbers computed with the uniform distribution. The function $y$ is a quadratic polynomial in $x$ with added stochastic noise according to the normal distribution $\\cal {N}(0,1)$.\n",
    "The following simple Python instructions define our $x$ and $y$ values (with 100 data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100,1)\n",
    "y = 2.0+5*x*x+0.1*np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your own code (following the examples under the [regression notes](https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/chapter1.html)) for computing the parametrization of the data set fitting a second-order polynomial. \n",
    "\n",
    "2. Use thereafter **scikit-learn** (see again the examples in the regression slides) and compare with your own code.   \n",
    "\n",
    "3. Using scikit-learn, compute also the mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE(\\boldsymbol{y},\\boldsymbol{\\tilde{y}}) = \\frac{1}{n}\n",
    "\\sum_{i=0}^{n-1}(y_i-\\tilde{y}_i)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the $R^2$ score function.\n",
    "If $\\tilde{\\boldsymbol{y}}_i$ is the predicted value of the $i-th$ sample and $y_i$ is the corresponding true value, then the score $R^2$ is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R^2(\\boldsymbol{y}, \\tilde{\\boldsymbol{y}}) = 1 - \\frac{\\sum_{i=0}^{n - 1} (y_i - \\tilde{y}_i)^2}{\\sum_{i=0}^{n - 1} (y_i - \\bar{y})^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we have defined the mean value  of $\\boldsymbol{y}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{y} =  \\frac{1}{n} \\sum_{i=0}^{n - 1} y_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the functionality included in scikit-learn. If you feel for it, you can use your own program and define functions which compute the above two functions. \n",
    "Discuss the meaning of these results. Try also to vary the coefficient in front of the added stochastic noise term and discuss the quality of the fits.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exercise: Normalizing our data\n",
    "\n",
    "A much used approach before starting to train the data is  to preprocess our\n",
    "data. Normally the data may need a rescaling and/or may be sensitive\n",
    "to extreme values. Scaling the data renders our inputs much more\n",
    "suitable for the algorithms we want to employ.\n",
    "\n",
    "**Scikit-Learn** has several functions which allow us to rescale the\n",
    "data, normally resulting in much better results in terms of various\n",
    "accuracy scores.  The **StandardScaler** function in **Scikit-Learn**\n",
    "ensures that for each feature/predictor we study the mean value is\n",
    "zero and the variance is one (every column in the design/feature\n",
    "matrix).  This scaling has the drawback that it does not ensure that\n",
    "we have a particular maximum or minimum in our data set. Another\n",
    "function included in **Scikit-Learn** is the **MinMaxScaler** which\n",
    "ensures that all features are exactly between $0$ and $1$. The\n",
    "\n",
    "\n",
    "The **Normalizer** scales each data\n",
    "point such that the feature vector has a euclidean length of one. In other words, it\n",
    "projects a data point on the circle (or sphere in the case of higher dimensions) with a\n",
    "radius of 1. This means every data point is scaled by a different number (by the\n",
    "inverse of its length).\n",
    "This normalization is often used when only the direction (or angle) of the data matters,\n",
    "not the length of the feature vector.\n",
    "\n",
    "The **RobustScaler** works similarly to the StandardScaler in that it\n",
    "ensures statistical properties for each feature that guarantee that\n",
    "they are on the same scale. However, the RobustScaler uses the median\n",
    "and quartiles, instead of mean and variance. This makes the\n",
    "RobustScaler ignore data points that are very different from the rest\n",
    "(like measurement errors). These odd data points are also called\n",
    "outliers, and might often lead to trouble for other scaling\n",
    "techniques.\n",
    "\n",
    "\n",
    "It also common to split the data in a **training** set and a **testing** set. A typical split is to use $80\\%$ of the data for training and the rest\n",
    "for testing. This can be done as follows with our design matrix $\\boldsymbol{X}$ and data $\\boldsymbol{y}$ (remember to import **scikit-learn**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training and test data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the standard scaler to scale our data as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we want you to to compute the MSE for the training\n",
    "data and the test data as function of the complexity of a polynomial,\n",
    "that is the degree of a given polynomial. We want you also to compute the $R2$ score as function of the complexity of the model for both training data and test data.  You should also run the calculation with and without scaling. \n",
    "\n",
    "One of \n",
    "the aims is to reproduce Figure 2.11 of [Hastie et al](https://github.com/CompPhysics/MLErasmus/blob/master/doc/Textbooks/elementsstat.pdf).\n",
    "\n",
    "\n",
    "\n",
    "Our data is defined by $x\\in [-3,3]$ with a total of for example $100$ data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "n = 100\n",
    "maxdegree = 14\n",
    "# Make data set.\n",
    "x = np.linspace(-3, 3, n).reshape(-1, 1)\n",
    "y = np.exp(-x**2) + 1.5 * np.exp(-(x-2)**2)+ np.random.normal(0, 0.1, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $y$ is the function we want to fit with a given polynomial.\n",
    "\n",
    "\n",
    "Write a first code which sets up a design matrix $X$ defined by a\n",
    "fifth-order polynomial.  Scale your data and split it in training and\n",
    "test data.\n",
    "\n",
    "\n",
    "\n",
    "Perform an ordinary least squares and compute the means squared error\n",
    "and the $R2$ factor for the training data and the test data, with and\n",
    "without scaling.\n",
    "\n",
    "\n",
    "\n",
    "Add now a model which allows you to make polynomials up to degree\n",
    "$15$.  Perform a standard OLS fitting of the training data and compute\n",
    "the MSE and $R2$ for the training and test data and plot both test and\n",
    "training data MSE and $R2$ as functions of the polynomial\n",
    "degree. Compare what you see with Figure 2.11 of Hastie et al. Comment\n",
    "your results. For which polynomial degree do you find an optimal MSE\n",
    "(smallest value)?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0745226bf50e84e61ca8064cbfbdd5f1d2020aec28ee54077b601fa43252eb4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
